{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f422f360",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-02T13:44:47.425681Z",
     "iopub.status.busy": "2021-09-02T13:44:47.424610Z",
     "iopub.status.idle": "2021-09-02T13:44:48.734394Z",
     "shell.execute_reply": "2021-09-02T13:44:48.733080Z",
     "shell.execute_reply.started": "2021-08-30T08:33:25.386079Z"
    },
    "papermill": {
     "duration": 1.363325,
     "end_time": "2021-09-02T13:44:48.734587",
     "exception": false,
     "start_time": "2021-09-02T13:44:47.371262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2598853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:44:48.796622Z",
     "iopub.status.busy": "2021-09-02T13:44:48.791245Z",
     "iopub.status.idle": "2021-09-02T13:44:48.851084Z",
     "shell.execute_reply": "2021-09-02T13:44:48.850500Z",
     "shell.execute_reply.started": "2021-08-30T08:33:26.580455Z"
    },
    "papermill": {
     "duration": 0.092834,
     "end_time": "2021-09-02T13:44:48.851246",
     "exception": false,
     "start_time": "2021-09-02T13:44:48.758412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap4(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train, test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['wap4'] = calc_wap4(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.std],\n",
    "        'wap2': [np.sum, np.std],\n",
    "        'wap3': [np.sum, np.std],\n",
    "        'wap4': [np.sum, np.std],\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "        'wap_balance': [np.sum, np.max],\n",
    "        'price_spread':[np.sum, np.max],\n",
    "        'price_spread2':[np.sum, np.max],\n",
    "        'bid_spread':[np.sum, np.max],\n",
    "        'ask_spread':[np.sum, np.max],\n",
    "        'total_volume':[np.sum, np.max],\n",
    "        'volume_imbalance':[np.sum, np.max],\n",
    "        \"bid_ask_spread\":[np.sum,  np.max],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88152db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:44:48.902434Z",
     "iopub.status.busy": "2021-09-02T13:44:48.901682Z",
     "iopub.status.idle": "2021-09-02T13:45:25.862757Z",
     "shell.execute_reply": "2021-09-02T13:45:25.862209Z"
    },
    "papermill": {
     "duration": 36.989144,
     "end_time": "2021-09-02T13:45:25.862911",
     "exception": false,
     "start_time": "2021-09-02T13:44:48.873767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/seven-fhg/seven.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c05e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:25.916336Z",
     "iopub.status.busy": "2021-09-02T13:45:25.915692Z",
     "iopub.status.idle": "2021-09-02T13:45:28.790081Z",
     "shell.execute_reply": "2021-09-02T13:45:28.790650Z",
     "shell.execute_reply.started": "2021-08-30T08:33:26.649017Z"
    },
    "papermill": {
     "duration": 2.905059,
     "end_time": "2021-09-02T13:45:28.790826",
     "exception": false,
     "start_time": "2021-09-02T13:45:25.885767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train_p, test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "train_stock_ids = train_p['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "#train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "#train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "#train = get_time_stock(train)\n",
    "test = get_time_stock(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d605c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:28.847165Z",
     "iopub.status.busy": "2021-09-02T13:45:28.846466Z",
     "iopub.status.idle": "2021-09-02T13:45:28.857573Z",
     "shell.execute_reply": "2021-09-02T13:45:28.856930Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.754348Z"
    },
    "papermill": {
     "duration": 0.041008,
     "end_time": "2021-09-02T13:45:28.857718",
     "exception": false,
     "start_time": "2021-09-02T13:45:28.816710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace by order sum (tau)\n",
    "#train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "#train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "#test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "#train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "#train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "#train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "#test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
    "#train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121a9639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:28.918287Z",
     "iopub.status.busy": "2021-09-02T13:45:28.917545Z",
     "iopub.status.idle": "2021-09-02T13:45:28.920731Z",
     "shell.execute_reply": "2021-09-02T13:45:28.920189Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.790286Z"
    },
    "papermill": {
     "duration": 0.03931,
     "end_time": "2021-09-02T13:45:28.920875",
     "exception": false,
     "start_time": "2021-09-02T13:45:28.881565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "# delta tau\n",
    "#train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e4101d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:28.985612Z",
     "iopub.status.busy": "2021-09-02T13:45:28.984907Z",
     "iopub.status.idle": "2021-09-02T13:45:28.987855Z",
     "shell.execute_reply": "2021-09-02T13:45:28.988355Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.821174Z"
    },
    "papermill": {
     "duration": 0.043231,
     "end_time": "2021-09-02T13:45:28.988523",
     "exception": false,
     "start_time": "2021-09-02T13:45:28.945292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames = [col for col in list(train.columns)\n",
    "            if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\",\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1' }]\n",
    "len(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69c90e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:29.042141Z",
     "iopub.status.busy": "2021-09-02T13:45:29.041439Z",
     "iopub.status.idle": "2021-09-02T13:45:31.643987Z",
     "shell.execute_reply": "2021-09-02T13:45:31.643091Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.834125Z"
    },
    "papermill": {
     "duration": 2.630242,
     "end_time": "2021-09-02T13:45:31.644167",
     "exception": false,
     "start_time": "2021-09-02T13:45:29.013925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d854229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:31.706744Z",
     "iopub.status.busy": "2021-09-02T13:45:31.706047Z",
     "iopub.status.idle": "2021-09-02T13:45:31.818169Z",
     "shell.execute_reply": "2021-09-02T13:45:31.818916Z",
     "shell.execute_reply.started": "2021-08-30T09:16:37.275415Z"
    },
    "papermill": {
     "duration": 0.147791,
     "end_time": "2021-09-02T13:45:31.819165",
     "exception": false,
     "start_time": "2021-09-02T13:45:31.671374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2f2613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:31.884599Z",
     "iopub.status.busy": "2021-09-02T13:45:31.881659Z",
     "iopub.status.idle": "2021-09-02T13:45:31.893217Z",
     "shell.execute_reply": "2021-09-02T13:45:31.892570Z",
     "shell.execute_reply.started": "2021-08-30T09:16:37.484812Z"
    },
    "papermill": {
     "duration": 0.046554,
     "end_time": "2021-09-02T13:45:31.893366",
     "exception": false,
     "start_time": "2021-09-02T13:45:31.846812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "#train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23eae5f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:32.084929Z",
     "iopub.status.busy": "2021-09-02T13:45:32.083765Z",
     "iopub.status.idle": "2021-09-02T13:45:32.089786Z",
     "shell.execute_reply": "2021-09-02T13:45:32.088938Z",
     "shell.execute_reply.started": "2021-08-30T09:16:46.1145Z"
    },
    "papermill": {
     "duration": 0.17059,
     "end_time": "2021-09-02T13:45:32.089934",
     "exception": false,
     "start_time": "2021-09-02T13:45:31.919344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887207d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T13:45:32.157987Z",
     "iopub.status.busy": "2021-09-02T13:45:32.152730Z",
     "iopub.status.idle": "2021-09-02T14:13:38.292732Z",
     "shell.execute_reply": "2021-09-02T14:13:38.292214Z",
     "shell.execute_reply.started": "2021-08-30T09:16:46.238183Z"
    },
    "papermill": {
     "duration": 1686.175725,
     "end_time": "2021-09-02T14:13:38.292882",
     "exception": false,
     "start_time": "2021-09-02T13:45:32.117157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428698\ttraining's RMSPE: 0.198264\tvalid_1's rmse: 0.00043934\tvalid_1's RMSPE: 0.203917\n",
      "[500]\ttraining's rmse: 0.000406922\ttraining's RMSPE: 0.188193\tvalid_1's rmse: 0.000425343\tvalid_1's RMSPE: 0.19742\n",
      "[750]\ttraining's rmse: 0.000392958\ttraining's RMSPE: 0.181735\tvalid_1's rmse: 0.000416835\tvalid_1's RMSPE: 0.193471\n",
      "[1000]\ttraining's rmse: 0.000383231\ttraining's RMSPE: 0.177236\tvalid_1's rmse: 0.000412414\tvalid_1's RMSPE: 0.191419\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383231\ttraining's RMSPE: 0.177236\tvalid_1's rmse: 0.000412414\tvalid_1's RMSPE: 0.191419\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428993\ttraining's RMSPE: 0.198747\tvalid_1's rmse: 0.000440615\tvalid_1's RMSPE: 0.203082\n",
      "[500]\ttraining's rmse: 0.000407104\ttraining's RMSPE: 0.188606\tvalid_1's rmse: 0.000425637\tvalid_1's RMSPE: 0.196179\n",
      "[750]\ttraining's rmse: 0.000393167\ttraining's RMSPE: 0.182149\tvalid_1's rmse: 0.000417598\tvalid_1's RMSPE: 0.192474\n",
      "[1000]\ttraining's rmse: 0.000383155\ttraining's RMSPE: 0.177511\tvalid_1's rmse: 0.000413187\tvalid_1's RMSPE: 0.190441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383155\ttraining's RMSPE: 0.177511\tvalid_1's rmse: 0.000413187\tvalid_1's RMSPE: 0.190441\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.00042857\ttraining's RMSPE: 0.198198\tvalid_1's rmse: 0.000465998\tvalid_1's RMSPE: 0.21632\n",
      "[500]\ttraining's rmse: 0.000406577\ttraining's RMSPE: 0.188027\tvalid_1's rmse: 0.000452588\tvalid_1's RMSPE: 0.210095\n",
      "[750]\ttraining's rmse: 0.000392918\ttraining's RMSPE: 0.18171\tvalid_1's rmse: 0.000445178\tvalid_1's RMSPE: 0.206655\n",
      "[1000]\ttraining's rmse: 0.000382983\ttraining's RMSPE: 0.177116\tvalid_1's rmse: 0.000441555\tvalid_1's RMSPE: 0.204973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382983\ttraining's RMSPE: 0.177116\tvalid_1's rmse: 0.000441555\tvalid_1's RMSPE: 0.204973\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.00042854\ttraining's RMSPE: 0.198538\tvalid_1's rmse: 0.0004457\tvalid_1's RMSPE: 0.205425\n",
      "[500]\ttraining's rmse: 0.000406238\ttraining's RMSPE: 0.188205\tvalid_1's rmse: 0.00043002\tvalid_1's RMSPE: 0.198198\n",
      "[750]\ttraining's rmse: 0.000392756\ttraining's RMSPE: 0.18196\tvalid_1's rmse: 0.000422586\tvalid_1's RMSPE: 0.194771\n",
      "[1000]\ttraining's rmse: 0.000382971\ttraining's RMSPE: 0.177426\tvalid_1's rmse: 0.000418005\tvalid_1's RMSPE: 0.19266\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382971\ttraining's RMSPE: 0.177426\tvalid_1's rmse: 0.000418005\tvalid_1's RMSPE: 0.19266\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429751\ttraining's RMSPE: 0.198779\tvalid_1's rmse: 0.000442733\tvalid_1's RMSPE: 0.205379\n",
      "[500]\ttraining's rmse: 0.000407766\ttraining's RMSPE: 0.188609\tvalid_1's rmse: 0.000428896\tvalid_1's RMSPE: 0.19896\n",
      "[750]\ttraining's rmse: 0.000394267\ttraining's RMSPE: 0.182366\tvalid_1's rmse: 0.000421757\tvalid_1's RMSPE: 0.195648\n",
      "[1000]\ttraining's rmse: 0.000383985\ttraining's RMSPE: 0.17761\tvalid_1's rmse: 0.000417711\tvalid_1's RMSPE: 0.193771\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383985\ttraining's RMSPE: 0.17761\tvalid_1's rmse: 0.000417711\tvalid_1's RMSPE: 0.193771\n",
      "Our out of folds RMSPE is 0.19472436203237878\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429995\ttraining's RMSPE: 0.198864\tvalid_1's rmse: 0.00044097\tvalid_1's RMSPE: 0.204673\n",
      "[500]\ttraining's rmse: 0.000411379\ttraining's RMSPE: 0.190254\tvalid_1's rmse: 0.00042727\tvalid_1's RMSPE: 0.198315\n",
      "[750]\ttraining's rmse: 0.000400295\ttraining's RMSPE: 0.185128\tvalid_1's rmse: 0.000419939\tvalid_1's RMSPE: 0.194912\n",
      "[1000]\ttraining's rmse: 0.00039203\ttraining's RMSPE: 0.181306\tvalid_1's rmse: 0.000415117\tvalid_1's RMSPE: 0.192674\n",
      "[1250]\ttraining's rmse: 0.000385825\ttraining's RMSPE: 0.178436\tvalid_1's rmse: 0.000412171\tvalid_1's RMSPE: 0.191307\n",
      "[1500]\ttraining's rmse: 0.000380504\ttraining's RMSPE: 0.175975\tvalid_1's rmse: 0.000410096\tvalid_1's RMSPE: 0.190343\n",
      "[1750]\ttraining's rmse: 0.00037595\ttraining's RMSPE: 0.173869\tvalid_1's rmse: 0.000408728\tvalid_1's RMSPE: 0.189708\n",
      "[2000]\ttraining's rmse: 0.000371976\ttraining's RMSPE: 0.172031\tvalid_1's rmse: 0.000408157\tvalid_1's RMSPE: 0.189443\n",
      "Early stopping, best iteration is:\n",
      "[1963]\ttraining's rmse: 0.000372484\ttraining's RMSPE: 0.172266\tvalid_1's rmse: 0.000407978\tvalid_1's RMSPE: 0.18936\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429777\ttraining's RMSPE: 0.199111\tvalid_1's rmse: 0.00043904\tvalid_1's RMSPE: 0.202357\n",
      "[500]\ttraining's rmse: 0.000410305\ttraining's RMSPE: 0.190089\tvalid_1's rmse: 0.000424362\tvalid_1's RMSPE: 0.195591\n",
      "[750]\ttraining's rmse: 0.00039904\ttraining's RMSPE: 0.184871\tvalid_1's rmse: 0.000416874\tvalid_1's RMSPE: 0.19214\n",
      "[1000]\ttraining's rmse: 0.000391081\ttraining's RMSPE: 0.181183\tvalid_1's rmse: 0.000412883\tvalid_1's RMSPE: 0.190301\n",
      "[1250]\ttraining's rmse: 0.000384919\ttraining's RMSPE: 0.178329\tvalid_1's rmse: 0.000410158\tvalid_1's RMSPE: 0.189045\n",
      "[1500]\ttraining's rmse: 0.000379509\ttraining's RMSPE: 0.175822\tvalid_1's rmse: 0.000408139\tvalid_1's RMSPE: 0.188114\n",
      "[1750]\ttraining's rmse: 0.000375094\ttraining's RMSPE: 0.173776\tvalid_1's rmse: 0.000407074\tvalid_1's RMSPE: 0.187623\n",
      "[2000]\ttraining's rmse: 0.000371297\ttraining's RMSPE: 0.172018\tvalid_1's rmse: 0.000406151\tvalid_1's RMSPE: 0.187198\n",
      "[2250]\ttraining's rmse: 0.000367599\ttraining's RMSPE: 0.170304\tvalid_1's rmse: 0.000405523\tvalid_1's RMSPE: 0.186908\n",
      "[2500]\ttraining's rmse: 0.000364118\ttraining's RMSPE: 0.168691\tvalid_1's rmse: 0.000404788\tvalid_1's RMSPE: 0.18657\n",
      "Early stopping, best iteration is:\n",
      "[2569]\ttraining's rmse: 0.000363212\ttraining's RMSPE: 0.168272\tvalid_1's rmse: 0.000404566\tvalid_1's RMSPE: 0.186467\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429479\ttraining's RMSPE: 0.198618\tvalid_1's rmse: 0.000460582\tvalid_1's RMSPE: 0.213806\n",
      "[500]\ttraining's rmse: 0.000410066\ttraining's RMSPE: 0.18964\tvalid_1's rmse: 0.000448347\tvalid_1's RMSPE: 0.208126\n",
      "[750]\ttraining's rmse: 0.00039897\ttraining's RMSPE: 0.184509\tvalid_1's rmse: 0.00044447\tvalid_1's RMSPE: 0.206326\n",
      "Early stopping, best iteration is:\n",
      "[912]\ttraining's rmse: 0.000393391\ttraining's RMSPE: 0.181929\tvalid_1's rmse: 0.000440114\tvalid_1's RMSPE: 0.204304\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429367\ttraining's RMSPE: 0.198921\tvalid_1's rmse: 0.000445544\tvalid_1's RMSPE: 0.205353\n",
      "[500]\ttraining's rmse: 0.000409807\ttraining's RMSPE: 0.189859\tvalid_1's rmse: 0.000430835\tvalid_1's RMSPE: 0.198573\n",
      "[750]\ttraining's rmse: 0.000398661\ttraining's RMSPE: 0.184695\tvalid_1's rmse: 0.000423338\tvalid_1's RMSPE: 0.195118\n",
      "[1000]\ttraining's rmse: 0.000390886\ttraining's RMSPE: 0.181093\tvalid_1's rmse: 0.000419446\tvalid_1's RMSPE: 0.193324\n",
      "[1250]\ttraining's rmse: 0.000384773\ttraining's RMSPE: 0.178261\tvalid_1's rmse: 0.000416692\tvalid_1's RMSPE: 0.192055\n",
      "[1500]\ttraining's rmse: 0.000379357\ttraining's RMSPE: 0.175752\tvalid_1's rmse: 0.000414921\tvalid_1's RMSPE: 0.191238\n",
      "Early stopping, best iteration is:\n",
      "[1487]\ttraining's rmse: 0.000379665\ttraining's RMSPE: 0.175894\tvalid_1's rmse: 0.000414695\tvalid_1's RMSPE: 0.191134\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000430212\ttraining's RMSPE: 0.198992\tvalid_1's rmse: 0.000442301\tvalid_1's RMSPE: 0.205179\n",
      "[500]\ttraining's rmse: 0.000411341\ttraining's RMSPE: 0.190263\tvalid_1's rmse: 0.000430151\tvalid_1's RMSPE: 0.199542\n",
      "[750]\ttraining's rmse: 0.00040012\ttraining's RMSPE: 0.185073\tvalid_1's rmse: 0.000423743\tvalid_1's RMSPE: 0.19657\n",
      "[1000]\ttraining's rmse: 0.000392336\ttraining's RMSPE: 0.181473\tvalid_1's rmse: 0.000420765\tvalid_1's RMSPE: 0.195188\n",
      "[1250]\ttraining's rmse: 0.000385898\ttraining's RMSPE: 0.178495\tvalid_1's rmse: 0.000418258\tvalid_1's RMSPE: 0.194025\n",
      "Early stopping, best iteration is:\n",
      "[1302]\ttraining's rmse: 0.000384715\ttraining's RMSPE: 0.177947\tvalid_1's rmse: 0.000417619\tvalid_1's RMSPE: 0.193729\n",
      "Our out of folds RMSPE is 0.19309621709759334\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEWCAYAAADGuvWEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAB4MElEQVR4nO2dd5iV1dW37x8goCAQBAyoFAsdHRVRoiJYsCsqkSQkiOWzKyavGBONYnntBRQT30gIxoJgwxoVhbGgIqAoRVAUFFBBVBCUMsD6/tj7zJxzOGfmDEyDWfd1nWueZz+7rGdTzpq91/ptmRmO4ziO4zgVRY3KNsBxHMdxnOqFOx+O4ziO41Qo7nw4juM4jlOhuPPhOI7jOE6F4s6H4ziO4zgVijsfjuM4juNUKO58OI7jVFEk/VXSiMq2w3HKGrnOh+M42yKSFgA7AxuSitua2Vdb2Oc5Zvbqllm39SFpCLCnmf2+sm1xtn585cNxnG2ZE82sftJnsx2PskBSrcocf3PZWu12qi7ufDiOU62Q1FDSvyR9LWmxpBsl1YzP9pA0QdJ3kpZJekRSo/jsIaAl8JykVZKukNRT0qK0/hdIOjJeD5H0hKSHJf0IDCxu/Ay2DpH0cLxuLckknSlpoaQfJJ0v6QBJH0laLml4UtuBkiZJGi5phaQ5ko5Iet5C0rOSvpc0T9L/Sxs32e7zgb8C/eK7fxjrnSnpY0krJX0u6bykPnpKWiTpfyQtje97ZtLz7SXdKemLaN9bkraPzw6S9HZ8pw8l9dyMP2qnCuPOh+M41Y1RwHpgT2BfoDdwTnwm4GagBdAB2A0YAmBmfwC+pGg15bYcxzsZeAJoBDxSwvi5cCCwF9APGApcBRwJdAJOl3RYWt3PgCbAtcBTkhrHZ48Bi+K79gVuknR4Frv/BdwEjInvvk+ssxQ4AWgAnAncLWm/pD5+CTQEdgHOBu6T9Iv47A5gf+BXQGPgCmCjpF2AF4AbY/nlwJOSmpZijpwqjjsfjuNsy4yLvz0vlzRO0s7AccBlZvaTmS0F7gZ+A2Bm88xsvJmtNbNvgbuAw7J3nxPvmNk4M9tI+JLOOn6O3GBma8zsFeAnYLSZLTWzxcCbBIcmwVJgqJkVmNkYYC5wvKTdgIOBP8e+pgMjgAGZ7Daz1ZkMMbMXzOwzC7wOvAIcmlSlALg+jv8isApoJ6kGcBYwyMwWm9kGM3vbzNYCvwdeNLMX49jjgalx3pxtBN/HcxxnW6ZPcnCopG7AdsDXkhLFNYCF8fnOwDDCF+iO8dkPW2jDwqTrVsWNnyNLkq5XZ7ivn3S/2FKzCr4grHS0AL43s5Vpz7pmsTsjko4lrKi0JbzHDsCMpCrfmdn6pPufo31NgLqEVZl0WgG/lnRiUtl2wMSS7HG2Htz5cBynOrEQWAs0SftSTHATYEAXM/teUh9geNLz9PTAnwhfuADE2I307YHkNiWNX9bsIklJDkhL4FngK6CxpB2THJCWwOKktunvmnIvqQ7wJGG15BkzK5A0jrB1VRLLgDXAHsCHac8WAg+Z2f/bpJWzzeDbLo7jVBvM7GvC1sCdkhpIqhGDTBNbKzsStgZWxNiDwWldLAF2T7r/BKgr6XhJ2wFXA3W2YPyyphlwqaTtJP2aEMfyopktBN4GbpZUV9LehJiMh4vpawnQOm6ZANQmvOu3wPq4CtI7F6PiFtRI4K4Y+FpTUvfo0DwMnCjp6FheNwav7lr613eqKu58OI5T3RhA+OKcTdhSeQJoHp9dB+wHrCAEPT6V1vZm4OoYQ3K5ma0ALiTESywmrIQsoniKG7+smUwITl0G/C/Q18y+i89+C7QmrII8DVxbgn7J4/Hnd5LejysmlwJjCe/xO8KqSq5cTtiimQJ8D9wK1IiO0cmE7JpvCSshg/Hvq20KFxlzHMfZBpE0kCCIdkhl2+I46bgn6TiO4zhOheLOh+M4juM4FYpvuziO4ziOU6H4yofjOI7jOBWK63w4Tg40atTI9txzz8o2o8rw008/Ua9evco2o8rg85GKz0cq1Xk+pk2btszMNpHGd+fDcXJg5513ZurUqZVtRpUhPz+fnj17VrYZVQafj1R8PlKpzvMh6YtM5b7t4jiO4zhOheLOh+M4juM4FYo7H47jOI7jVCjufDiO4ziOU6G48+E4juM4ToXizofjOI7jVBM2bNjAvvvuywknnJBSfumll1K/fv3C+z/+8Y/k5eWRl5dH27ZtadSoUeGzmjVrFj476aSTNssOT7V1KhVJlwH/NLOfN6PtEGCVmd2RQ93rgTfST+2U1BO43MxOyNTOcRxnW2LYsGF06NCBH3/8sbBs6tSp/PDDDyn17r777sLre++9lw8++KDwfvvtt2f69OlbZIevfDiVzWXADuU9iJldU8Jx4Y7jONs0ixYt4oUXXuCcc84pLNuwYQODBw/mtttuy9pu9OjR/Pa3vy1TW3zlw6kwJNUDxgK7AjWBx4EWwERJy8ysl6TfAn8FBLxgZn+ObY8BbortlpnZEWl9/z/gVOBUM1udYexRwPNm9kTsayjwM/BWLravLthA6ytfKP1Lb6P8T5f1DPT5KMTnIxWfj1Qqez4W3HI8AJdddhm33XYbK1euLHw2fPhwTjrpJJo3b56x7RdffMH8+fM5/PDDC8vWrFlD165dqVWrFldeeSV9+vQptU3ufDgVyTHAV2Z2PICkhsCZQC8zWyapBXArsD/wA/CKpD7AJOABoIeZzZfUOLlTSRcDRwF9zGxtcQZIqhv7OhyYB4wppu65wLkATZo05Zou60v/xtsoO28f/kN1Aj4fqfh8pFLZ85Gfn88777xDQUEBK1euZPr06Xz33Xc88cQTjBgxgqFDh5Kfn8+GDRvIz89PaTt69Gi6d+/Om2++mVLWtGlTvvrqK84//3x++ukndtlll9IZZWb+8U+FfIC2wAKCg3FoLFsANInXJwP/Sap/NnAXcCLwSIb+hgAfAS8A25Uw9iigL5BHiP1IlJ9EWBEp1va2bduaU8TEiRMr24Qqhc9HKj4fqVSF+bjyyittl112sVatWtnOO+9s22+/vTVq1Mh23nlna9WqlbVq1cok2R577JHSLi8vzyZNmpS13zPOOMMef/zxrM+BqZbh/1SP+XAqDDP7BNgPmAHcKOmaMuh2BtCasJXjOI7jZODmm29m0aJFLFiwgMcee4zDDz+cH374gW+++YYFCxawYMECdthhB+bNm1fYZs6cOfzwww907969sOyHH35g7dqwwLxs2TImTZpEx44dS22POx9OhRG3VX42s4eB2wmOyEpgx1jlPeAwSU0k1QR+C7wOvAv0kNQm9pO87fIBcB7wbOy/JOYArSXtEe/LNorKcRxnG+Gxxx7jN7/5DZIKyz7++GO6du3KPvvsQ69evbjyyis3y/nwmA+nIukC3C5pI1AAXAB0B16S9JWFgNMrgYkUBZw+A4XxF09JqgEsJcR4AGBmb0m6HHhB0lFmtiybAWa2Jvb1gqSfgTcpcn4cx3G2eXr27JnxlN1Vq1al3A8ZMmSTOr/61a+YMWPGFtvgzodTYZjZy8DLacVTgXuT6owGRmdo+1/gv2llQ0roO7nuwKTrl4D2pTLecRzHKTN828VxqjjpioT9+/enXbt2dO7cmbPOOouCgoLCuvn5+eTl5dGpUycOO+ywyjLZcRynWNz5cLYpJN0naXra58zKtmtLSCgSJujfvz9z5sxhxowZrF69mhEjRgCwfPlyLrzwQp599llmzZrF448/XlkmO47jFIs7H2WApEaSLiyhTmtJv8uhr9aSZpahbQMlDS+r/qoiks6Q9KmkT4H3zCwv7fPvpLrtJb0jaW2ME6nSZFIkPO6445CEJLp168aiRYsAePTRRzn11FNp2bIlAM2aNasUmx3HcUrCYz7KhkbAhcDfi6nTGvgd8GgF2FNtiJkv1wJdAQOmSXrWzH7I0uR74FKgT2nGqQyF0wW3HJ9RkTBBQUEBDz30EMOGDQPgk08+oaCggJ49e7Jy5UoGDRrEgAEDKtRmx3GcXHDno2y4BdhD0nRgfCw7lvBleKOZjYl1OsQ6DwJPAw8B9WL9i83s7ZIGkvQucLaZzYr3+cDlwOfASGB3gmz4uWb2UVrbUUSJ8Xi/yszqx8PVrgOWEzJSxhL0MwYB2xOUQz+T1BS4H2gZu7zMzCZlsfMwYFi8NaAHQbm08BC3uCIz1cxGSVpACDQ9FlhPUBa9GdgTuN3M7s8yJUcD483s+9jneIKS6uhMkuxmthRYKun4LP0lv0OlKpzefPPNmygSJqsP3nHHHey+++6FqoRffPEFc+fO5c4772TdunVcdNFFSGK33XYrc9tWrVq1iRJidcbnIxWfj1R8PjbFnY+y4Uqgs5nlSToNOB/YB2gCTJH0RqyT/MW7A3BUTP3ci/DF2zWHscYApwPXSmoONDezqZLuBT4wsz6SDgf+Q1DzzJV9gA6ElYHPgRFm1k3SIOASwgFww4C7Y2prS0J2SYcs/V0OXGRmkyTVB9bkYMOXcQ7vJiiSHgzUBWYSnJ5M7AIsTLpfBOwSHaWskuy5YGb/BP4J0K5dO7uk/8ml7WKL+Mtf3mXatGkMHDiQNWvW8OOPPzJixAgefvhhrrvuOmrVqsXYsWOpUSPsnr777rvsvffeHHvssQA8++yz1K1bN2NK3ZaSn59fLv1urfh8pOLzkYrPx6Z4zEfZcwgw2sw2mNkSgkjWARnqbQc8IGkG4YC1XFVaxhJkwiE4IU8kjfsQgJlNAHaS1KAUdk8xs68tnI3yGfBKLE8oiAIcCQyPqzfPAg2iY5GJScBdki4FGplZLssGzyaNOdnMVprZt8BaSY1K8S4ABxFk1OcDJFZGtiYyKRI+/PDDjBgxgpdffpnRo0cXOh4AJ598Mm+99Rbr16/n559/ZvLkySmBqo7jOFUFX/moPP4ILCGsONQgt5UBzGyxpO8k7Q30I6yy5Mr6OBZRrKt20rPkA9k2Jt1vpOjvSQ3gIDMr0VYzu0XSC8BxwCRJRyePH6mb1ix5zHR7sv1dXQz0TLrfFcgvyb6tmfPPP59WrVoVSh6feuqpXHPNNXTo0IFjjjmGvffemxo1anDOOefQuXPnSrbWcRxnU9z5KBuSJcLfBM6T9CDQmBDrMJiwPZCspNkQWGRmGyWdQYhLyJUxwBVAw6S4jjeB/sANMYZjmZn9mCyLSzjEbX/C6slJhNWX0vAKYQvmdgBJeWY2PVNFSXuY2QxghqQDCKJe04COkuoQYkmOIMcj7YvhZeAmSb+I972BvxDm8++S2iS2XbbG1Y8EyYqE69dnX0QaPHgwgwcPriCrHMdxNg93PsoAM/tO0qSYIvtfwkmrHxICLa8ws28kfQdskPQhIZ7h78CTkgYALwE/lWLIJwjxFzcklQ0BRkr6iBBwekaGdg8Az0QbSjsmhCyR++IYtYA3yL7ycpmkXoRVi1nAf81sraSxhBiO+YRzWbYIM/te0g3AlFh0fVLw6SaS7JJ+SVBVbQBslHQZ0NHMftxSWxzHcZzcUDjx1nGc4mjXrp3NnTu33MdZs2YNPXr0YO3ataxfv56+ffty3XXXceihhxam2y5dupRu3boxbtw4VqxYwe9//3u+/PJL1q9fz+WXX86ZZ5a/ppoH0KXi85GKz0cq1Xk+JE0zs02SKXzlw3GqEHXq1GHChAnUr1+fgoICDjnkEI499ljefPPNwjqnnXYaJ58cMm/uu+8+OnbsyHPPPce3335Lu3bt6N+/P7Vr1842hOM4TqXj2S5VFElHZ5AJf7ocxxshqdTnIks6M4Odr+V4vH22Po+SNE3SjPjzcEldMowzOdZ/SdKHkmZJul9SsfEzsf5ySc9vro3lhSTq1w8JRAUFBRQUFKQcZ/3jjz8yYcIE+vTpU1h/5cqVmBmrVq2icePG1Krlv1M4jlO18f+lqiglndJaDuOdU3KtjO3+Dfw7uSwKn7UAvtpMc5YBJ5rZV5I6Ay+b2S5k1y05PQbXihAP82vgsWL6vx3YATgvV4MqSuF0wS3Hs2HDBvbff3/mzZvHRRddxIEHHlj4fNy4cRxxxBE0aBCyqC+++GJOOukkWrRowcqVKxkzZkxK+q3jOE5VxJ2PaoikeoSMl10JWSE3ABcQhMFaANfHqtsDtc2sjaT9gbuA+gTnYKCZfZ2h774EsbRHJK0GuhOyfU6M/b0NnGdmllBnjSJpTQhqp63NLDkQdRawvaQ6UYNkE5KCRWsR0oct2rInQZysKbAB+LWZfWZmr8WMoJLmqcIVThMqiEOHDmXVqlX87W9/o3379rRp0wYI2yzHHXdcYb3XX3+dJk2a8Oijj/LVV19xzjnnMGLECOrVq5dlhLLBFRtT8flIxecjFZ+PDJiZf6rZBzgNeCDpviFBG6NrWr2xwEWElNy3gaaxvB8wspj+U/oCGiddP0RY1UipR1CDXZChr77Aqzm808vAD4Szc2rGssnAKfG6LrBDUv2eBKn5nOasbdu2Vhlcd911dvvtt5uZ2bfffmuNGze21atXFz4/7rjj7I033ii879Wrl02ePLnc7Zo4cWK5j7E14fORis9HKtV5Pgi/VG7yf6qvz1ZPZhDSTm+VdKiZrUivIOkKYLWZ3Qe0AzoD46O66dWEVZNc6SVpclRzPRzolEsjSZ2AW8lhe8TMjgaaA3WAwyXtCOxiZk/H52vM7OdS2FwpfPvttyxfvhyA1atXM378eNq3bw/AE088wQknnEDdukXabC1btuS1114DYMmSJcydO5fdd9+9wu12HMcpDb7tUg0xs08k7UdQH71R0mvJzyUdSYib6JEoAmaZWffSjiWpLkHTpKuZLZQ0hCJl02TF07pp7XYlHL43wMw+y/G91kh6BjgZeLe0tlYFvv76a8444ww2bNjAxo0bOf300znhhBMAeOyxx7jyyitT6v/tb39j4MCBdOnSBTPj1ltvpUmTJpVhuuM4Ts6481ENiZko35vZw5KWA+ckPWsF3AccbWarY/FcoKmk7mb2jqTtgLYWT9bNQLLia8KpWBbPgelL0Xk0CwiKq+9RdF4N8RyXF4ArLcupuUl16wM7mtnXkmoBxwNvmtlKSYsk9TGzcVFVtWZVX/3Ye++9+eCDzNprmfaMW7RowSuvvLJpZcdxnCqMb7tUT7oA78UtlGuBG5OeDQR2AsbFdNYXzWwdwTm4NaqjTgd+VUz/o4D7Y/9rCcqqMwlxGVOS6t0BXCDpA0LMR4KLgT2Ba5LSaptlGase8GxUXZ1OUDJNnID7B+DS+Oxt4JcAkt4kHOZ3RHRQji7mXRzHcZwyxlc+qiGWOY23Z/w5FbguQ5vpFG3DlNT/k8CTSUVXx096vTnA3mn1MLMbSXWIihtrCZlPDcbMPiXEmKSXH5pL347jOE754CsfjlOFWLNmDd26dWOfffahU6dOXHvttUDISrvqqqto27YtHTp04J577ilsk5+fT15eHp06deKwww6rLNMdx3Fyxlc+nM1G0n3AwWnFwywIj5XHeJMJ2SzJ/MHC6bnbBNnk1T/++GMWLlzInDlzqFGjBkuXLgVg+fLlXHjhhbz00ku0bNmysNxxHKcqU24rH5JWlVffJYx7maQdyrjPCpPjljQqCnVttuR5Wn+t42m7ZYKkgZKGA5jZRWaWl/b5t6Sekn6V1OZ8hdN7s76fpL+WNLaZHZhhvBnZ/nwktYkpvvMkjZFUO5bXiffz4vPWZTU/W0o2efV//OMfXHPNNYXqpc2ahRCYRx99lFNPPZWWLVumlDuO41RltsqVD0k1zWxDlseXAQ8TjpXPtb9aZlacfGWp5bhjv8XZWSK2mZLnVYCewCpCkCdmdn+mSmnv91fgps0cL9ufz63A3Wb2mKT7gbOBf8SfP5jZnpJ+E+v1K26AipBXX3DL8QAZ5dU/++wzxowZw9NPP03Tpk2555572Guvvfjkk08oKCigZ8+erFy5kkGDBjFgwIBytdNxHGdLKXfnI563cRtwLEH2+kYzGyOpBjCcEBC4ECggqGY+kaWfBcAY4CjgNknfEwIj6wCfAWcCZxHkwSdKWmZmvSStMrP6sY++wAlmNlDSKGANsC8wSVJj4EeCNPgvgSsStliOcty52mlmqyRdQwbJ8bS+8tkMyfNYPjLWLzYPU9K7wNmJtNmkMT+PfexOcOTONbOP0tqeSAgSrQ18B/SP9p0PbJD0e+AS4AhglZndkeX9+hIk1KcT5NQ/I6QCD431/hdYambDMr1Dpj+f+PfucOB3sehBYAjB+Tg5XkNI+x0uSRnmv0Ll1ZNTadPl1X/++WcWL17MHXfcwRtvvMFpp53GPffcwxdffMHcuXO58847WbduHRdddBGS2G233crVVpeLTsXnIxWfj1R8PjKQSfa0LD6ELxsIUt7jCWeI7Ax8SVCi7Au8SNj6+SVBGrtvMf0tIDgEENIy3wDqxfs/A9ck1WuSbocVSXWPitejgOcpkuIeRUi/rAF0BOaljd+THOS4S2FnNsnxUYl5YDMlz4GPgB7x+nZgZjH2/hG4Ll43B+bG63uBa+P14cD0eD0QGB6vfwEoXp8D3BmvhxDObCH9Ptv7pf05tQbej9c1CM7ITiXMe8qfT5z7eUn3uyXmgZD2u2vSs8+S/85k+lS2vHq7du3s888/NzOzjRs3WoMGDczM7Oabb7ZrrrmmsP5ZZ51lY8eOLXe7qrNcdCZ8PlLx+UilOs8HlSivfggw2sw2WEiLfJ2QGnkI8LiZbTSzb4CJOfQ1Jv48iOAgTIq/LZ8BtNoM2x631G2RcdGe2QRHaXPJxc5SS47nInkeBboamdkbsdlDJXQ7liKBr9MpEgA7JNHWzCYAO0lqkNZ2V+Dl+A6Dc3mHXDCzBcB3kvYFegMfmNl3ZdF3VSebvHqfPn2YODH8E3n99ddp27YtACeffDJvvfUW69ev5+eff2by5Ml06NChssx3HMfJia0t5uOn+FPAeDP7bQ5tkpfS66Y9+yntPvnUVJXStkz9ZrSzBMnxjOQqeR6dj5wxs8WSvpO0N2H15PxSNL8XuMvMno3bHkNKM3YJjCCssvySoi2k0vAd0CgpnmdXYHF8tpiwErIoqqI2jPUrnWzy6occcgj9+/fn7rvvpn79+owYMQKADh06cMwxx7D33ntTo0YNzjnnHDp37lzJb+E4jlM8FeF8vAmcJ+lBoDHhy3MwIQbijFjelLBs/miOfb4L3CdpTzObp3BE/C5m9glF0t7LYt0lkjoQJMJPic8riox2ElQ4IbPk+CaolJLnMfPjEDN7ixCHURJjgCuAhlYU1/FmbHtDdCyWmdmPIZSikIYUfaGfkVS+EkhfJSmJAknbmVlBvH+aEOeyHUVxGzljZiZpImFuH4v2PRMfPxvv34nPJ8TlwUonm7x6o0aNeOGFzAGvgwcPZvDgweVtmuM4TplREdsuTxNiED4EJhDiIb4hKGAuAmYTslPeBzY5XTUTZvYt4bfi0VE6+x2gfXz8T+Cl+MUDcCUhtuNt4OvNeYHNlePOZqeZLSe75HgmBlI6yfMzCU7PdHJbwXkC+A1hCybBEGD/aPctpDoXyXUelzSNImcP4DnglGhrrmqi/wQ+kvQIQHy/icBYKyFjqJg/nz8Df5I0jzB//4rl/yJsI80D/kT4O+I4juNUEKrMX/gk1beQ+bET4XCxg6Nj4lRzYjbU+8CvLcikVyrt2rWzuXPnlusYa9asoUePHqxdu5b169fTt29frrvuOgYOHMjrr79Ow4YNARg1ahR5eXn88MMPnHXWWXz22WfUrVuXkSNHVtiWS35+Pj179qyQsbYGfD5S8flIpTrPh6RpZtY1vbyyYz6ejzEKtYEb3PFwAKLw2PPA01XB8agosqmbAtx+++307ds3pf5NN91EXl4eTz/9NHPmzOGiiy7itddeqwzTHcdxSkWlKpyaWU8LKpUdzWxUbPe0ik4yTXxyPnVUFaRwuqV2FjNWuSicSjo6g71Pb0Z/hQqnxdTZIoVTM5ttZrub2f8k9dElg/2TJeVJekfSLEkfSeqX1KaNtiKFU2VRN83G7NmzOfzwcG5e+/btWbBgAUuWLKkQWx3HcbaEyl752AQzO6WkOqoCCqdlYGeJWBkqnFrmk2zLi56UscKphfNb8tLLJbUFBpjZp5JaANMkvRzjarYahdPi1E3/8Y9/cNVVV3H99ddzxBFHcMstt1CnTh322WcfnnrqKQ499FDee+89vvjiCxYtWsTOO29JlrjjOE75U24xH4rKolL5KJwC2RRO7yBkgpRK4ZSQiZNR4TS27UkQyjqhhPcu0U4rRuE02vW8mT2hslM4PdbMMgYDqJQKp5IGElKEL1Z2hdN3gQ3At6QpnGZ5v76EDKgZbIbCadr7fBj7mxfH/6WZrZfUHRhiZkdLejlev6OQavsNQaytOIXT/a8Z+kBJw282XXZpmHKfUDe99NJLadCgAY0bN6agoIA777yTFi1acMYZZ/DTTz8xfPhwPv30U3bffXe+/PJLLr/8cvbcc89yszPZvsQqjePzkY7PRyrVeT569eqVMebDFU5d4XSbUDiNdbsBH8c2W73CaULdNJmJEyfa8ccfv0ndjRs3WqtWrWzFihUVYlt1VmzMhM9HKj4fqVTn+cAVTjPiCqfbiMKppObR3jPNbGNZ2FHRZFM3/frrkCFuZowbN64wo2X58uWsW7cOgBEjRtCjRw8aNCitvIrjOE7FU+ViPkrAFU5d4XQTolP0AnCVmb0bi7c6hdNs6qaHH3443377LWZGXl4e998fQmg+/vhjzjjjDCTRqVMn/vWvf5UwguM4TtXAFU7LF1c4zZ3NUjiNGSxPA/+xpBgds61P4TSbuumECRMy1u/evTuffPJJeZvlOI5T5rjCaQ7IFU6rssLp6QSHdmBSCm5efOYKp47jOFUQVzh1qiSqZgqn2dRNE1x66aWMHDmSVauCfM5dd93FiBEjqFWrFk2bNmXkyJG0arU5YU+bR3VWbMyEz0cqPh+pVOf5UBaF04pY+SiO5+Nv52/iCqdOREF4bB7wWlVwPCqChLrphx9+yPTp03nppZd4990QvjJ16lR++OGHlPr77rsvU6dO5aOPPqJv375cccUVlWG24zjOZlGpzoeVg8JpRbG12JlAJSicqgzUVJP6GhgFvzaXXQip170lTZN0uLIonMbx/lfSQuWgqhvrj5S0VNLMLbCxTFEWddMNGzYwePBgbrvttpT6vXr1YocdgpDvQQcdxKJFiyrcZsdxnM2lymW7WA7KoVWBrcXOBFaCwqmVoZoqIUZlJvDVZrZfRtA9+UpSZ+BlM9uFDAqnkecIgnW5rpKMivX/k6tB5alwWpy66bBhwzjppJNo3rx51vb/+te/Cs+AcRzH2Rqo1JgPp3KIWTdjCemnNYEbgAvYDDXVDH33JXy5LwZWA90J2U2Z1FzzCeJjUyU1IYjRtE7rT4Q02OZmlpwKnem9CtVs4/3OwP0ElVaAC8zs7fisNUE0LusxsBWlcJpN3XTgwIGMGDGCoUOHUrNmTY499lj++9//ptQdP348Tz/9NEOHDqV27drlYl8mqrNiYyZ8PlLx+UilOs9HNoXTKrfy4VQIxwBfmdnxAJIaEpwPzOxZQioqksYCr8c03nuBk83sW4XD2/6XIGefggXZ9IuJTkXsZ7iZXR+vHwJOIKxW5MJpBLXTYh2PLNwDvG5mp0iqSXCccsbM/knIwqHl7nvanTPK55/Lgv49Nyl7//33Wb58Od9++y1nn302AGvXruWcc85h3rx5ALz66qs89dRTvP766zRr1qxcbMtGdQ6gy4TPRyo+H6n4fGyKOx/VkxnAnZJuJfz2/2aafkeKmmrc+kioqUJYLSlN2nKv2N8OBK2XWeTgfEjqRDj0rXcpxkrmcGAAQEzXzSmVOxPbb1eTuXF7pDz49ttv2W677WjUqFGhuumf//xnvvmmKAa7fv36hY7HBx98wHnnncdLL71U4Y6H4zjOluLORzXEzD6RtB9wHHCjpNeSn+eqppoLKl7NdT1FQc9109rtStCIGWBmn5V23K2NbOqm2Rg8eDCrVq3i17/+NQAtW7bk2WefrShzHcdxtgh3PqohMRPlezN7WNJywqFwiWelUlPNMkRCZRaKnIpMaq4LgP0JGi+J82USEvEvAFea2aQteNXXCNtJQxPbLma22asf5Uk2ddNkEhofELZcHMdxtlYqW+fDqRy6AO9FjZVrgRuTng2kdGqqmRgF3B/7X0t2Ndc7gAskfUA4hTbBxcCewDVJabVZ9xYk3SZpEbBDVKAdEh8NImz5zACmEQ75Q9Jogtpsu1j/7GLexXEcxyljfOWjGpIl7bZn/DkVuC7tGWY2naJtmJL6f5Ign5/g6vhJrzcH2DutHmZ2I6kOUUnjXUE4mya9fAlwcobyXA4kdBzHccoJX/lwnEpmzZo1dOvWjX322YdOnTpx7bXXAtC/f3/atWtH586dOeussygoKEhpN2XKFGrVqsUTT2Q9k9BxHKdK4s6Hs9lIui+D6uiZ5Tje5AzjdSmv8SqKbNLq/fv3Z86cOcyYMYPVq1czYsSIwjYbNmzgz3/+M717b24ikOM4TuXhzkcZIKmRpAtLqNNaUtaj4dPqlZnsd5Q6H15W/SVjZhdFefzkz7/LY6w43oEZxpsh6SVJyyU9X1IfknaSNFHSqvKal9KSTVr9uOOOQxKS6NatW4qE+r333stpp53mabaO42yVeMxH2dAIuJCQUpqN1sDvgEcrwJ7qxu0EDZHzcqi7BvgbQbckq7ppOuUlr16ctHqCgoICHnroIYYNGwbA4sWLefrpp5k4cSJTpkzJ2K/jOE5Vxp2PsuEWYI+Y3TE+lh0LGHCjmY2JdTrEOg8SNCweAurF+hcnpL+LQ9K7wNmJNNeERDnwOTCSICX+M3CumX2U1nYUQVTsiXi/yszqS+pJCDJdTsiEGUsQIhtEkETvY2afSWpKkCtvGbu8LFsqrKTDgGHx1gjBqvsTlE9PiHWGEyTVR0laAIyO87aeIGt+MyHr5XYzuz/bnJjZa/Ed0m04INpQj5B1c4SZrQTekrRntv6S2ifLq3NNl/UlNSk1+fn5hddDhw4tlFZv3749bdq0AeCOO+5g9913Z8OGDeTn5zNkyBD69evHG2+8wTfffMOsWbNo0qRJlhHKh1WrVqXYXt3x+UjF5yMVn48MmJl/tvBDWNWYGa9PIzggNYGdgS+B5oRskueT2uwA1I3XexG+hFP6yjLWH4Hr4nVzYG68vhe4Nl4fDkyP1wOB4fF6FNA3qa9V8WdPguPRHKhDOJclMcYgYGi8fhQ4JF63BD4uxs7ngIPjdX2Co5s+B8MJZ8RA0Py4IF7fDXxE0AppCizJ4c8gve/aBIfsgHjfAKiV9LxwXnL5tG3b1iqK6667zm6//XYzMxsyZIidfPLJtmHDhsLnrVu3tlatWlmrVq2sXr161rRpU3v66acrzD4zs4kTJ1boeFUdn49UfD5Sqc7zkfhuS//4ykfZcwgw2oKc9xJJrwMHAD+m1dsOGC4pD9gAtM2x/7HAKwR9jtMpEuw6hOD4YGYTYmxDg1LYPcXiQXGSPotjQFgB6RWvjwQ6JkmxN5BU38wyHWU/CbhL0iPAU2a2KF3CPQMJic4ZBEGwlcBKSWslNTKz5aV4n3bA12Y2BcDM0ue/ypBNWn3EiBG8/PLLvPbaa9SoURSeNX/+/MLrgQMHcsIJJ9CnT59KsNxxHGfzcOej8vgjsATYhxD4uyaXRma2WNJ3kvYG+gHnl2LMQjlzSTUIqwMJkg9u25h0v5Givyc1gIPMrERbzewWSS8QJNwnSTqaVDl1SJNUTxsz3Z5t9u9qNmn1WrVq0apVK7p3D6r2p556Ktdcc00lW+s4jrPlbLP/oVcwyXLibwLnSXqQcIhaD8KR8rsk1QFoCCwys42SziBs0+TKGIKoVkMriut4E+gP3BDjH5aZ2Y9pqw0LCHEXY4GTCKsvpeEV4BJCgCeS8iyIj22CpD3MbAYwI8ZetCeqjEqqQ4glOQJ4q5Q25MpcoLmkA8xsiqQdCQfllX3gxhaSTVp9/fqSTR01alQ5WOQ4jlO+uPNRBpjZd5ImxRTZ/xLiFT4kBFpeYWbfSPoO2BDlyUcRMmOelDQAeAn4qRRDPkEIpLwhqWwIMFLSR4SA0zMytHsAeCbaUNoxAS4F7otj1ALeIPvKy2WSehFWLWYB/zWztZLGEqTW5wPFH2aSI5LeJDg39aPM+tlm9rKkfsC9krYHVhO2jVbF4NYGQG1JfYDeZja7LGxxHMdxSkYhHsRxnOJo166dzZ07t1z6XrNmDT169GDt2rWsX7+evn37ct1119G/f3+mTp3KdtttR7du3fi///s/ttuuaLFqypQpdO/enccee4y+ffsWM0LZk5+fT8+ePSt0zKqMz0cqPh+pVOf5kDTNzLqml7vImONUMq5w6jhOdcO3XaooMUDz1rTi+WZ2SgntrgfeMLMKOXM9yqkPSiueZGYXlUHfq8ysfrzuQtBFSWatmR24acuti+IUThNkUzh1kTHHcbZG3Pmooljmk2eLRVJNM6vQdAgLcuqbSKpLqlWWwZ0xeDWvrPorLa5w6jiOU3a487GVIKk1IUh0GrAfIYhzADCbkP1yFHCbpGOIKqaZFD4Jwai3EES56gD3mdn/ZRmzeey7AeHvygVm9qakVYTg1d7AN8BvzOzbqLY6nah1Eu/vIoiMLSMIin0t6f8RlENrA/OAP5jZz5LaEITM6gPPlDAfWW1LWi3pC5xgZgOjuutqYF+gGXBWnL/uwGQzG5hhDFc4zYIrNqbi85GKz0cqPh8ZyKQ85p+q9yEonxpFqqEjCbLqCwgZNYl6o4C+ZFH4JHyZXh3L6gBTgTZZxvwf4Kp4XRPYMV4b0D9eX0ORgmo+8Pd4vR3wNtA03vcDRsbrnZLGuBG4JF4/CwyI1xcRFVhLaduqpDp9gVFJ8/IYIOBkguhbF0Lc0zQgr7j5d4XTVKqzYmMmfD5S8flIpTrPB65wuk2w0IrOUnmYkPoKYQUgnYwKn5J6A3vHVQEIeiN7EVJf05lCSN/dDhhnRZoeG5PGfBh4KqlNorwd4eC28VFrpCbwdXzWWdKNhAP56lO0vXQwUaWVEN+RHvOSi23F8ZyZmaQZBMn2GQCSZhGcu1z6KHNc4dRxnOqGOx9bF+l50Yn70uh1iLDSUGI8iZm9IakHcDwwStJdZvafEuxK2CJglpl1z1B/FOGwug8lDSRsAWXqa3NsS26/VSiousKp4zjVDXc+ti5aSupuZu8AvyOog+6bpW5GhU/CKsMFkiaYWYGktsBiM9vEgZHUiqDC+kBUJd0P+A9hq6IvYRsjYUem8Zsm7I0rFG0tnMa7I/B1LOtPOMgOwnkwvyGspvQvbiKKsW2JpA5x/FMI6rNVGlc4dRynuuE6H1sXc4GLJH0M/AL4R7aKZraOEGdxb1Q0HU9YCRhBCFJ9Pyqy/h/ZndCewIeSPoh9DYvlPwHdYvvDgeuzjN8XuDWOPx34VXz8N2AywdmYk9RsUHy/GQQ5+uLIZtuVwPOEeJOvMzd1HMdxKpVMgSD+qXofQkzCzMq2I9qSNRB0W/2UR8Dpl19+aT179rQOHTpYx44dbejQoWZmNn36dDvooIOsc+fOdsIJJ9iKFStS2n3xxRdWr169wqDUyqA6B9BlwucjFZ+PVKrzfJAl4DSnlQ9Je8SlbST1lHSppEbl4w45TvWgVq1a3HnnncyePZt3332X++67j9mzZ3POOedwyy23MGPGDE455RRuv/32lHZ/+tOfOPbYYyvJasdxnC0n122XJwmHou0J/BPYjaDHsFUjqXXcOqjocVtIeqKUzUYBA0sxRk9Jz+dYt4uk6WmfydnqW9TRqAhysU3SSElLc/2zlPSSpOW5zk950bx5c/bbbz8AdtxxRzp06MDixYv55JNP6NGjBwBHHXUUTz75ZGGbcePG0aZNGzp16lQpNjuO45QFuTofGy2oVZ4C3Gtmg4Hm5WfWto2ZfWVmFXsSWDGY2Qwzy0v7VAnZ8hxtGwUcU4pubwf+UGZGlgELFizggw8+4MADD6RTp04880zQWHv88cdZuHAhEISKbr31Vq699trKNNVxHGeLyTXbpUDSbwnHtJ8Yy7Yrpn6lIekWgh7GffF+CCFAshlwLCEV80YzG5PWbiDQ1cwujvfPA3eYWX5U9PwHcBwhiPGvwG1AS+AyM3tWUk1yVw5tTVAh7RzH7UNQId0LuIMgEPYHQjrocWb2fWz6B0kjCH9uZ5nZe5K6EYIt6xKyWc40s5TjV7PViWOfBOwA7AE8bWZXxDbHADcR9DmWmdkRkuoB9xL0O7YDhphZRiVSSZ0Isuu1CU7uaUBB4r1jncuB+mY2JKqhfgAcGudiAPAXghDYGDO7OtM4UJh22zqDDXsC9wNNgQ3Ar83sMzN7TVLPbP1loqzl1ROy6hCcitNOO42hQ4fSoEEDRo4cyaWXXsoNN9zASSedRO3atQEYMmQIf/zjHwvPgXEcx9laydX5OBM4H/hfM5sfZbDTD/mqKowBhgL3xfvTCWJVvYF9gCbAFElvlKLPesAEMxss6WmCKudRQEfgQYIy59nACjM7IMbHTJL0ipllEu9KpzMhZbYuQW78z2a2r6S7CV/CQ2O9HcwsL+pbjIzt5gCHmtl6SUcSHIbT0vovrk5eHHstMFfSvcAagnx6j/jn3TjWvSrOw1kx5uc9Sa9ahjRdwt+XYWb2iKTaBCdm5xLmYZ2ZdZU0iCCvvj/wPfCZpLvN7LsS2qfzCHCLmT0tqS6lzO4qT3n1hNTy+vXr+ctf/sKBBx5I48aNC8v/+te/ArBw4UKaNWtGfn4+r7zyCg8//DCXXnopq1atokaNGixcuJBTTin2rMFyweWiU/H5SMXnIxWfj03Jyfkws9mS/kz4TZ/4hVqc+mSlYWYfSGomqQXhN94fCF+wo81sA0EH4nXgAOCjHLtdRzhXBWAG4TTVgpgS2jqWl0Y5NJ2JZrYSWClpBfBc0lh7J9UbHd/xDUkNogOwI/CgpL0IqzqZVqQaFlPnNTNbASBpNtCKkMb7RsJxSlp56Q2cFFcsIDhLLYGPM4z5DnCVpF2Bp8zs06h0WhzPJr33LDP7Otr1OSHOKGfnI+qa7GJmT8d3WJNr2wRm9k9CjBPt2rWzS/qfXNouSuqfM844g4MPPpihQ4cWli9dupRmzZqxceNGBg4cyODBg+nZsycffVT013XIkCHUr1+fyy+/PEPP5U9+fj49e/aslLGrIj4fqfh8pOLzsSm5ZrucSNBpeCne50l6tthGlcvjBI2JfmSWHs/EelLnI1kdsyCmDEGSOqaZJStjJpRDE3EJbczslRzHTlfbTFbiTHYQMymc3kBwXjoTtsTSVT0poU7y2Bso3iEVcFrSO7Y0s0yOB2b2KGFLZzXwoqTDKX6Ok22pUgqk5cWkSZN46KGHmDBhAnl5eeTl5fHiiy8yevRo2rZtS/v27WnRogVnnnlmZZvqOI5TpuT6H/oQoBvh4DDMbLqk3cvJprJgDGHboAlwGOHk0vMkPQg0BnoAg0n98lsAXCipBkHgqlspx8xZOXQL6AdMlHQIYYtnhaSGFCmEDszSLpc6ybwL/F1Sm8S2S1z9eBm4RNIlZmaS9jWzTaU5gfj343Mzu0dSS8IKzptAM0k7AauAEyhaUSpTzGylpEWS+pjZuLgVVtPMfi6P8TaHQw45hCKfNpVBgwYV23bIkCHlYJHjOE7FkOseeEFiaT6JjWVtTFlhRRLei+PS/dOELZYPgQmEU2C/SWs2ibBFMhu4B3i/lMOWRjl0c1kTFT3vJ8SYQAh8vTmWZxsvlzqFmNm3hFiHp6I6aWL16AbCls1HCoex3VBMN6cDMyVNJ8Sm/MfMCghqqO8RFFfnZG+eO5JGE7Z52kWHIzE3fwAulfQRQfH0l7H+m4TVsSNi/aPLwg7HcRwnN5TtN6+UStK/gNcI0tWnEU5T3c7Mzi9f8xynatCuXTubO3duyRWrCb6HnYrPRyo+H6lU5/mQNM3MuqaX57rycQnQibAP/yiwAriszKxznGrIwoUL6dWrFx07dqRTp04MGxaOp/nwww/p3r07Xbp04cQTT+THH38EYPz48ey///506dKF/fffnwkTJlSm+Y7jOJtNiUvwUb/iBTPrRUi1dHJEUhc2TUleW1UEvMqCuGWRnvk038zKNP8zxom8luHREZuRglslSMir77fffqxcuZL999+fo446inPOOYc77riDww47jJEjR3L77bdzww030KRJE5577jlatGjBzJkzOfroo1m8eHHJAzmO41QxSlz5iOmpG2Ngo1MKqrJyaDqSRkjqWNp2ZvZy+jsCz8RU58215ShJ0yTNiD8PN7PvMsxlXrLjIenZXCTWt1Z59X333ZcWLcK0durUidWrV7N27drMnTuO41Rhcg2IXAXMkDSeoBYKgJldWi5WORWOmZ1Tht0NBGYCX21m+2XAiWb2laTOhCybXYprIOlUwt/TXLidoOp6Xq4GlafCKWSWV+/Tp0+KvHoyTz75JPvttx916tQpM5scx3EqilwDTs/IVG5mD5a5RU65E2XSxwK7EpRHbwAuAC4HWhAyUgC2B2qbWRtJ+wN3AfUJzsHAhAhYWt99CWetLCZofHQnpDWfGPt7GzgvpurmA5eb2VRJTQhHL7dO608EcbHmZpbx13xJ9Qkpu+cCY5Pk2zPKq8dnPePYJxQzT8kKp/tfM/SBbFVLTZddihYSV69ezaBBg/j9739Pjx49+PLLL7n33ntZsWIFBx98ME899VThWS8A8+fP5+qrr+a2225jl12K9cnKjVWrVrnMexI+H6n4fKRSneejV69eGQNOMTP/VLMPIWPpgaT7hgQNl65p9cYCFxHSa98GmsbyfsDIYvpP6QtonHT9EGFVI6UeQZNlQYa++gKvlvA+dxMOPWwNzEwqnwycEq/rEuTpE896Es6ZyWnO2rZta+XBunXrrHfv3nbnnXdmfD537lw74IADCu8XLlxoe+21l7311lvlYk+uTJw4sVLHr2r4fKTi85FKdZ4Pwi+Vm/yfmtO2i6T5bKquiZlVZaExJzszgDsl3Ur4An4zXfpc0hXAajO7L259dAbGx3o1CQfs5Uqv2N8OBJG3WRRJyGclHk6XOJcnW508YA8z+2Py4XJlIa9e3pgZZ599Nh06dOBPf/pTYXmyvPqNN97I+eeHjPbly5dz/PHHc8stt3DwwQdXltmO4zhbTK4xH8lLJnWBXxO+RJytEDP7RNJ+hFN6b5SUkkUSD5/7NUEJFoKs+iwz617aseKBbn8nrHAsVDhlOKEsmyy3Xjet3a4EcbgBFrdKstAd6CppAeHvc7O4nXNiMW2qBAl59S5dupCXlwfATTfdxKeffsp994VzEU899dRCefXhw4czb948rr/+eq6/PuyMvfLKKzRr1qxS7Hccx9lccj1YLj2VcaikacA1ZW+SU97ETJTvzexhScuBc5KetSKcCHy0ma2OxXOBppK6m9k7krYD2lpQks3ESoLCLBQ5FctibEZf4IlYtoBwcu17sTxhQyPgBeBKM5tU3LuY2T+Af8R2rQkrOT3j/TYlr3711Vdz9dVXl7dZjuM45U6uB8vtl/TpKul8tsGDvqoRXYD3ovT5tcCNSc8GAjsB4yRNl/Sima0jOAe3Rrn16cCviul/FHB/7H8t4ZydmYSslSlJ9e4gnIfzASHmI8HFwJ7ANdGG6ZI259d7l1d3HMepguTqQNyZdL2ecAbK6WVvjlMRmNnLBEcgmZ7x51TgugxtplO0DVNS/08CTyYVXR0/6fXmEA6cS66Hmd1IqkOUE2a2gBCbkrj/FDg8Q71DS9t3ebBw4UIGDBjAkiVLkMS5557LoEGD+PDDDzn//PNZtWoVrVu35pFHHqFBgwaMHz+eK6+8knXr1lG7dm1uv/12Dj98k9dzHMep8uTqfJxtZp8nF0hqUw72OE61wRVOHcepruR6tssTOZY5pUBSI0kXbmEfAyUNLyN7WkjK+c9V0n1J2yKJz5llYUuW8SZnGK+LpDbx2TxJYyTVLqGfkZKW5qKGWp64wqnjONWVYlc+JLUnHCjXMCpIJmhAWnaCs1k0Ai4kZIMUIqmWma2vaGPM7CuSAj9zqH9ROZqTabyM0vSSxgJ3m9ljku4HziYGoWZhFDAc+E+uY7vCqeM4TtlRrMKppJOBPsBJwLNJj1YCj5nZ2+Vq3TaOpMeAkwnZJAXAGuAHoL2ZtZU0DtiN4OgNM7N/xnZnAn8BlgMfEg6ru1hSU4KiZ8s4xGXZskUkHQYMi7dGiOfYiZAt0lnSCIpSrHcBhpvZdZIGE+J96gBPm9m1WfrfREXVzMbElNiuZrZMUlfgDjPrGVNw2wC7R/v/CBwEHEtQSz3RzAoyjCPgW+CXZrZeUndgiJkdLWnnOB8JPZoLEn9nkzJjOqf3mdS3K5xmoTorNmbC5yMVn49UqvN8bJHCKdA9l3r+KbXSaGuiIich4PMnoE3S88bx5/aEbJGdgObAlwTJ8NrAJIJjAPAocEi8bgl8XMzYzwEHx+v6hFWwQnuS6rUCPo4/ewP/JOh+1ACeB3pk6X8TFdX4cwHQJF53BfLj9RDgLYKa6j7Az8Cx8dnTQJ8s4zQB5iXd75Y0p2MIDhgEB6hhprnP5eMKp6lUZ8XGTPh8pOLzkUp1ng+2ROEU+EDSRYQtmMLtFjM7K8f2Tm68Z2bzk+4vlZQ4mn43YC9Cumi+mX0LIGkM0DbWORLomKRW2kBSfTPLdODaJOAuSY8AT5nZogwqp3UJKamXmNkXki4hOCAfxCr1o01vZOh/ExXVHN7/v2ZWIGkGwVl4Kamv1jm0T+dwYAAUns68YjP6KDfMXOHUcZzqSa4Bpw8RvvSOBl4nLKWvLC+jqjGFJwbHg8+OJKw67UP4wi8pzqYGcJAVHTe/SxbHAzO7hSAutj0wKcb3pHM/wTF5NWEWcHNS/3ua2b+y9P8JsB/BcbhRUkKQLquqKUETBDPbCBRErxlgI9njk74DGklKPN+VsE1T5UkonE6YMIG8vDzy8vJ48cUXGT16NG3btqV9+/a0aNEio8Jpov7SpUsr+S0cx3FKT64rH3ua2a8lnWxmD0p6FMjlN1mneJKVQNNpCPxgZj9Hx+CgWD4ZGCZpJ+BHggz6h/HZK8AlhCPjkZRnQZ9jEyTtYWYzgBmSDgDaE8TDEs8vAnaMTkqCl4EbJD1iZqsk7UJwEjb5BixGRXUBQdX0v4StmS3CzEzSREKg7GPAGUAiQOI1wmm9QyXVBOqbWZVZ/XCFU8dxqiu5rnwkAv2WKxwy1hDwAyW2EAuy9ZNiyuftaY9fAmpJ+hi4BXg3tvmaEB/xDmHr5OOkNpcSzjn5SNJs4Pxihr9M0syo/llAcAaSuRzokpTSer6ZvUKIK3knbo08QXbnKZuK6nUE52kq4Zj7suDPwJ8kzSPExSRWYwYRDrWbAUwDOgJIGk2Yv3ZR4fTsMrLDcRzHyYFcVz7+KekXwN8IWS/18XNdygQz+12W8rWETI9Mz/4N/DtD+TLCcfe5jHtJhuIFRIVQM8soImdmwyjKkimu/0wqqsTYj7YZyoek3dfP9ixD28+BbhnKlxCyidLLf1tcfxVBNnXT6dOnc/7557NmzRpq1arF3//+d7p1C6+Wn5/PZZddRkFBAU2aNOH111+v5LdwHMfZPHI9WG5EvHydorRFx3E2k2zqpldccQXXXnstxx57LC+++CJXXHEF+fn5LF++nAsvvJCXXnqJli1beqyH4zhbNbkeLLezpH9J+m+877gtLFVLal0ZKpelVRKNbfKjLkau9XtKel7SmRlUQe8rvdVZx9kpQ//TY0xKmSLp6QzjHC3pGElzo8LplTnYO1HSKpWRMuzmkE3dVBI//vgjACtWrChUNH300Uc59dRTadkySLg0a+a7no7jbL3kuu0yirDMf1W8/4SgoZAx08EpHiulkugWjpVxi6YM+/8OyCuv/tPGOiW9LAaSfgIcBSwCpkh61sxmZ+lmDWH7sDNJh9BVJsnqpkOHDuXoo4/m8ssvZ+PGjbz9dtDx++STTygoKKBnz56sXLmSQYMGMWDAgEq23HEcZ/PI1floYmZjJf0FwIKSZFkFC5Ypkm4BFprZffF+CCGFtRkhhsKAG81sTFq7gQTlzYvj/fME9c18SasIct3HAV8DfwVuIwh5XWZmz8YvwVsIYmF1gPvM7P+y2NiaIiXRgQQV2XoEzYw7COJhfyCknh5nZt/Hpn+IyqO1gLPM7D1J3QgxGHWB1cCZZjY3bbyMdeLYJwE7AHsQFEuviG2OAW4i6G0sM7MjomrpvYQv7e0ISqLPkAFJnQhOT23CCttphMDWQlVRSZcTMlCGSMonpBMfGudiAEHFtQswxsyypXl0I4iMfR77TKjGzo5ZPMNif2uBI8xsJfCWpD2z9JeRspRXT5ZWX7VqFaeddhpDhw6lQYMGXH311dx9992cdtppjB07lrPPPptXX32V9evXM23aNF577TVWr15N9+7dOeigg2jbdpPwGcdxnCpPrs7HT3EZ3QAkHUQVE2xKYgwwFEhsLZwO3EoQx9qHoIg5RVImYaxs1AMmmNlgSU8TMjeOImRPPEgIwj0bWGFmB0iqQ8hieSVNNCwbnYF9Cc7BPODPZravpLsJX8JDY70dzCxPUg9gZGw3Bzg0OoRHEhyG9BTW4urkxbHXAnMl3UtYHXiAoF46X1LjWPeqOA9nSWpEyGZ51cx+YlPOJ0jCP6Jw0FtNYOcS5mGdmXWVNIiQLrs/8D3wmaS74ypLOrsAyYefLAIOjGOOAfqZ2RRJDQiOV84oVV6da7qUzXE7+fn5AKxfv56//OUvHHjggTRu3Jj8/HxGjhzJKaecQn5+Pk2bNuWdd94hPz+fdevW0a5dO6ZMmQLAXnvtxaOPPkrPnj3LxKbSsmrVqsL3cHw+0vH5SMXnY1NydT7+RPiC3UPSJIK0d4VsG5QWM/tAUrOoM9GUcFZKHjA6qlwukfQ6cADwUY7driNVbXNtkhJn61jeG9hbUmJeGhJWMnJxPibG38hXSlpBkD5PjLV3Ur3R8R3fkNQgOgA7Ag9K2ovgHG6Xof+GxdR5LaF9EdNzWwG/AN5IOE5JKy+9gZPiigUEZ6klqem+Cd4BrpK0K0Go7FOlKahmIHF+0AxgVkwrRtLnBIXXTM5HNtoBX5vZlPgOP5aiLbHNPwly8rRr184u6b9J4sxmY2acccYZHHzwwQwdOrSwfLfddkMSPXv25LXXXqN9+/b07NmTnXfemYsvvphDDjmEdevW8eWXX3LbbbfRuXPl7Bzl5+dXmuNTFfH5SMXnIxWfj00p6VTblmb2pZm9r3AQWTuCyuVcy3DIVxXicYJz9EvCb78Z00bTSFbehFT1zXS1zUIlThUpa4ogQ75JemkOJJ+LvjHpPl3ZM12RyoAbCM7LKXE7Jz9D/8XVSR57A8X/nRBwWvq2TibM7FFJk4HjgRclnUeIzcg2x8m2JM9B4j6bXYsJjkmCrULhNKFu2qVLF/Ly8gC46aabeOCBBxg0aBDr16+nbt26/POf/wSgQ4cOHHPMMey9997UqFGDc845p9IcD8dxnC2lpJWPcQSJbAj77lusSFlBjCFsGzQBDgO6A+dJehBoTDjBdTCpX34LgAsl1SAs5W+iG1ECLwMXSJoQV0XaAouzbElsLv2AiZIOIWzxrJDUkKIv24FZ2uVSJ5l3gb9LapPYdomrHy8Dl0i6JCqL7mtmH2TqQNLuwOdmdo+kloQVnDeBZnELbxVwAkUrSpvLFGAvSW0I7/gb4HfAp0BzSQfEbZcdgdVmVjZ7J1tIceqm06ZNy1g+ePBgBg8eXJ5mOY7jVAglOR/J6+Rbjb6Hmc2KXzaLzezrGKfRnSBDbsAVZvZNXAVIMImwRTKbsI3wfimHHUHYgnlfKjzmvc+WvEcG1kj6gLBtkjjU7zbClsrVQLaIyFzqFGJm38Z4h6eiM7aUEONyAyH+5KNYPp/gQGTidEKAbAHwDXBTdMquB94jOApzSrIlB1vXS7qY4BjVBEaa2SwASf2AeyVtT4j3OBJYJWkB0ACoLakP0LuY7BjHcRynjFG2374AJL1vZvulXztOdaNdu3Y2d26Ju03VBt/DTsXnIxWfj1Sq83xImmZmm2hUlSQyto+kHyWtJART/pi4l1TqAD7HcQILFy6kV69edOzYkU6dOjFsWFCsnz59OgcddBB5eXl07dqV9957D4A5c+bQvXt36tSpwx133FGZpjuO42wxxW67mFnNijJkW0RSF+ChtOK1ZnZgZdhTHkg6mpDKnMz8TIJgWzjOToRTatM5IksKbpWmtPLqjRs35p577mHcuHGVbbrjOM4Wk2uqrbMZxCPr8yrbjlyI4mV3lTb2IdMBcpIGSmoRlVw3x5ajCIJttQlpzoPNbAJZ5jJqegwnCLxtBK4ysyeL6X8kIVZlaULwrKJp3rw5zZs3B3KTV2/WrBnNmjXjhRfKRujMcRynMnHnwwHAzM4pw+4GAjOBzXI+gGXAiWb2laTOBOdml2LqX0VwJNrGQNjGxdSFcFzAcOA/uRpUXgqnkJu8uuM4zrZEsQGnzrZJlEkfS9DEqEnIYrkAuBxoAVwfq24P1DazNpL2B+4C6hOcg4EJEbC0vvsSvtwXEzJMuhPSmk+M/b0NnBdTdfOBy81sqqQmwFQza53WnwjiYs3NLFn7I7nOQqB9elqzpJ2B+ynK1LrAzN6Oz1qTJPWepd9khdP9rxn6QLaqpaLLLg0Lr1evXs2gQYP4/e9/T48ePbjnnnvYZ599OOyww5g4cSLPP/88d955Z2H9UaNGsf3229OvX78ysWVzWbVqFfXr169UG6oSPh+p+HykUp3no1evXhkDTjEz/1SzD0Fa/YGk+4YE4bGuafXGAhcRUnvfBprG8n6ElNZs/af0BTROun6IsKqRUo+gybIgQ199gVeLGasRQV79LkJ69OPAzvHZGMLZOxCcrIZJ7VoDM3Ods7Zt21pZs27dOuvdu7fdeeedhWUNGjSwjRs3mpnZxo0bbccdd0xpc+2119rtt99e5raUlokTJ1a2CVUKn49UfD5Sqc7zQfilcpP/U0vKdnG2TWYAR0m6VdKhFuXVk5F0BUGU6z6Csm1nYLyk6cDVhFWTXOklaXKUoz8c6JRLI4XD6W4FziumWq1oy9sWUsHfIRzORxzrHwBmtiHTe1YWZsbZZ59Nhw4d+NOf/lRY3qJFC15//XUAJkyYwF577VVZJjqO45QbHvNRDTGzTyTtRzil90ZJKVkk8fC5XxOUYCGIzc0ys+6lHUtSXeDvhBWOhQqnDCeUZZMl7eumtdsVeBoYYGafFTPEd8DPwFPx/nHCIX9VmtLKq3/zzTd07dqVH3/8kRo1ajB06FBmz55NgwYNKvEtHMdxNg93Pqoh8dC9783sYUnLgXOSnrUinAh8tJklToGdCzSV1N3M3pG0HdDWopJoBlYSDryDIqdimaT6hG2UJ2LZAsLJte+RdFBhPDDvBeBKM5tU3LuYmUl6jpDpMgE4gqBSCyE19wJgqKSaQP2qsvpRWnn1X/7ylyxatKi8zXIcx6kQfNuletIFeC9uoVwL3Jj0bCCwEzBO0nRJL5rZOoJzcKukD4HpwK+K6X8UcH/sfy3hnJ2ZhKyVKUn17iCch/MBIeYjwcXAnsA10YbpkpoVM96fgSGSPgL+APxPLB9E2PKZAUwDOgJIGk3YnmknaZGkKr9S4jiOsy3hKx/VEMugzUFYOQCYClyXoc10irZhSur/SSBZZ+Pq+EmvN4dw4FxyPczsRlIdopLG+yKTbWa2BDg5Q/lvc+27vFi4cCEDBgxgyZIlSOLcc89l0KBB9OvXj4SM+/Lly2nUqBHTp09n3bp1nHfeeUydOpUaNWowbNiwaivX7DjO1o87H45TCWRTOB0zZkxhnf/5n/+hYcOQlvvAAyHNd8aMGSxdupRjjz2WKVOmUKOGL146jrP14f9zlQGSGkm6sIQ6rSX9Loe+WkuaWYa2DZQ0vKz6S+v7vqRtkcTnzPIYK443OcN4XeKzBnELpdh3ldRe0juS1kq6vLxsLYnmzZuz337hnMZkhdMEZsbYsWP57W/DIs3s2bM5/PDDgaB22qhRI6ZOnVrxhjuO45QBvvJRNjQCLiRkdWSjNfA74NEKsKdCMLOLKni84s7EuQF4I4duvgcuBfqUZuyKUjhN8Oabb7LzzjsXptrus88+PPvss/z2t79l4cKFTJs2jYULF9KtW7cysclxHKciceejbLgF2CMGWI6PZccCBtxoZmNinQ6xzoOENNKHgHqx/sUW1TeLQ9K7wNmJTJOESijwOTCSoOb5M3CumX2U1nYUQdXziXi/yszqS+pJiPNYTghGHUvQAhlEUCXtY2afSWpKUAxtGbu8LFs2iqTDgGHx1ggxGfsTFE1PiHWGEwRoRklaAIyO87aeoCx6MyHw9HYzu7+YOdkf2Bl4CeiaVH4McBNBYGyZmR1hZkuBpZKOz9hZar/JCqdc02V9SU1yIj8/v/A6oXB6zjnn8P777xeW33333XTr1q2w7h577MH48eNp3749O++8M+3bt+fjjz9O6asiWbVqVaWNXRXx+UjF5yMVn48MZFIe80+pFUNbE9UyCeqh4wlfeDsDXwLNCQGdzye12QGoG6/3IqrAUYLyJvBH4Lp43RyYG6/vBa6N14cD0+P1QGB4vB4F9E3qa1X82ZPgeDQH6hCk0RNjDAKGxutHgUPidUvg42LsfA44OF7XJzi66XMwnCDTDiHt9oJ4fTfwESFdtymwpJhxahCUUndNe9emBOXTNvG+cVq7IQRHKKc/44pSODUzKygosGbNmtnChQuztu3evbvNmjWrzG3Kleqs2JgJn49UfD5Sqc7zQRaFU1/5KHsOAUab2QZgiaTXgQOAH9PqbQcMl5QHbADa5tj/WOAVQors6RRpZhxCcHwwswmSdpJUGgWqKRbPapH0WRwDwgpIr3h9JNAxHLcCQANJ9c1sVYb+JgF3SXoEeMrMFiW1y8azSWPWN7OVwMoYn9HIzJZnaHMh8GKG/g8C3jCz+QBm9n1Jg1ckZpkVTgFeffVV2rdvz667FonI/vzzz5gZ9erVY/z48dSqVYuOHTtWtNmO4zhlgjsflccfgSXAPoTf3tfk0sjMFkv6TtLehDNWzi/FmIWKovH019pJz5IPbduYdL+Ror8nNYCDzKxEW83sFkkvEFRUJ0k6mlRFU0hTNU0bM92ebH9XuwOHxoDf+kBtSasIzk+VJZvC6XHHHcdjjz1WGGiaYOnSpRx99NHUqFGDXXbZhYceeqgSrHYcxykb3PkoG5IVPd8EzpP0IOFo9x6EU113SaoD4TC3RWa2UdIZhG2aXBkDXEE4KC0R1/Em0B+4IcZwLDOzH9NWAxYQ4i7GAicRVl9KwyvAJcDtAJLyLOh/bIKkPcxsBjBD0gFAe6LQl6Q6hFiSI4C3SmlDCmbWP2nMgQQZ9ytjfMrfJbUxs/mSGlel1Y/iFE5HjRq1SVnr1q0L9T8cx3G2dtz5KAPM7DtJk2KK7H8J8QofEgItrzCzbyR9B2yICqGjCJkxT0oaQAiU/Clz7xl5ghDMeUNS2RBgZFT5/Bk4I0O7B4Bnog2lHRNClsh9cYxahOySbCsvl0nqRVi1mAX818zWShpLUDudD3xQyvFzxsy+jQGjT8VVnqWEw/R+SRBSawBslHQZ0NHM0rfFHMdxnHJC2X77chyniHbt2pmvPBSRn5/vCqtJ+Hyk4vORSnWeD0nTzKxrermLjDlOJbBw4UJ69epFx44d6dSpE8OGhazkfv36kZeXR15eHq1bty6MBykoKOCMM86gS5cudOjQgZtvvrkSrXccx9kyfNslC5JaE9JCO6eVjwDuMrPZaeUDCfEGF5fB2D2BWwlpr8nMN7NTtrT/siLaOTTDo0lWxgJkUck0PcpyrUXhMUktgRHAboTtruPMbEGWvnYibF0dAIwqiz+z0lJaefXHH3+ctWvXMmPGDH7++Wc6duzIb3/7W1q3bl3RpjuO42wx7nyUEjM7p+RaZcK3FsW4ygtJNWNK8JawqLztBIjBq3nFVPkP8L9mNl5SfUKsSTbWAH8DOsdPhdO8eXOaN28OpMqrJ9JnzYK8+oQJEwCQxE8//cT69etZvXo1tWvXpkGD0mRSO47jVB3c+SieWlGnYj9C0OQA4EWCONXUeI7JXwgCXR+Smh6agqQTCae21ga+A/qb2ZIsSqDJ7Q4A/kkQB/ssQ7/ZlESvJ2Th7AlMBC6MmTWrgP8jaHZcFFd4Lo12TY71Nkj6B2FlYHvgCTO7No53DGG142dKyFSpKJVTSR2BWmY2HiBZdyTO3zCCkuxa4IioH/KWpD2Lsz+ZypZX79u3L8888wzNmzfn559/5u6776Zx48ZlYo/jOE5F485H8bQjSJlPkjSSIGgFgKTmBEny/YEVhC/44rI33iJoZJikcwipsv9DkEa/KI5RnyS9D0m/IiiXnmxmX2bpN1v7bkBH4AtCZsuphK2GesBkM/sfSR2APxOUSAsk/Z2Qrvsf4Coz+15STeC1qCvyCSFj5nBgHiHltziyvlsxfGlmeZLuJmQFHUzQA5lJkHbPRFtguaSngDbAq8CVhPTlMUA/M5sSRddW52ADULXk1WfMmMGyZcsYPXo0K1euZNCgQdSvX58WLVqUiU2lxeWiU/H5SMXnIxWfj01x56N4FlrR2SUPE1YIEhwI5JvZtwCSxlC8SumuwJjotNQmpJpCdiXQDoQVj95m9lUx/WZr/56ZfR5tG01QQH2CoKb6ZGx7BMF5mhLbbE9ISQU4PX751iLIrnckBCjPN7NPY78PE7+cS2lbcWyOymkt4FBgX4Kc/RiC1Pp7wNdmNgWgtOm0ZvZPwp8B7dq1s0v6n1ya5iVSUFDACSecwPnnn5+icrp+/Xr69evHtGnTClVOH3/8cc444wyOPPJIAJ577jlq1apVaRH01Tl6PxM+H6n4fKTi87Epnu1SPOl5yFuSl3wv4dyRLsB5RHVPM7sFOIfwxT9JUvtY/2vCSsG+xRqYvX0229ckxXkIeNDM8uKnnZkNkdSGsGpxhJntDbzApmqkJZLFtvJQOV1EOMvmczNbD4wjbJVVWUorr96yZcvC+I+ffvqJd999l/bt2+M4jrM14s5H8bSU1D1e/47UGIfJwGHxDJXtgF+X0FdDwoFtkCQAllACNbNbgSkEJVAIcSTHAzfHrJKMFNO+m6Q2UWCrH5njM14D+kpqFvtqLKkVQYDrJ2CFpJ0JMRgAc4DWkvaI979N7zAH274gqpxKakRYfdlSpgCNoqophG2h2cBcoHmM+0DSjpKqxGpfQl59woQJham1L774IkBGefWLLrqIVatW0alTJw444ADOPPNM9t5778ow3XEcZ4upEv8RV2HmEoIyRxK+zP4BnAhgZl9LGgK8Q3AUppfQ1xDgcUk/ABMIsQmQQQmUcF4JMSD1BOC/ks4ys8kZ+s3Wfgrh1NhEwOnT6Q3NbLakq4FXopNSQIjReFfSBwRnYyHxnBQzWxO3Yl6Q9DNB0n3H9H6Ls608VE5jgOzlhNgUEWTcHzCzdZL6AfdK2p4Q73EksCoGtzYgnAXTh7C9NTvzCGVPaeXV69evz+OPP17OVjmO41QMrnC6DRJXSgozSpwtxxVOU/E97FR8PlLx+UilOs+HK5w6ThWhtOqm3333Hb169aJ+/fpcfHGF66E5juOUOb7tUsZIuopN4z8eN7P/3cJ+zwQGpRVnVBI1s3wgf0vGKw2lsW0LxylW5XRrobTqpnXr1uWGG25g5syZzJw5s7LMdhzHKTPc+ShjopOxRY5Gln7/Dfy7rPtNkE02PhfSbYtS869sgS1HAbcQUpLXAYPNbEI2lVNJ+xM0QbYniMANsmL2EyW9BBwEvFUZW1OlVTetV68ehxxyCPPmzatoUx3HccoFdz4coMxl4wcSAkqL0ycpjmXAiWb2laTOwMvALsXU/wfw/wgZSC8CxxACb7NxO7ADIeU5J8pK4XRz1E0dx3G2Ndz5qIZIqgeMJQif1QRuAC4gaHu0IEizQ1hJqG1mbeLqwl1AfYJzMNDMvs7Qd1+gK/CIpNWEzJvBhCyh7YG3gfOi0ms+RVL1TQgy663NLDkDZhawvaQ6ZraJfH0UbWtgZu/G+/8AfQgZQnsSVFGbEsTVfm1mn5nZa8WlLyf1XeYKp5ujbppgzpw5LF68uEooJbpiYyo+H6n4fKTi85EBM/NPNfsApxFSURP3DQkxIl3T6o0FLgK2IzgNTWN5P2BkMf2n9AU0Trp+iLCqkVIPaAIsyNBXX+DVYsbqmvycoHT6fLyeDJwSr+sCOyTV65mol8unbdu2VpasW7fOevfubXfeeWdKeUFBgTVr1swWLly4SZt///vfdtFFF5WpHZvLxIkTK9uEKoXPRyo+H6lU5/kg/FK5yf+pvvJRPZkB3CnpVsIX8JvpsueSrgBWm9l9ceujMzA+1qtJUGDNlV6xvx2AxoTVjOdKaiSpE3Ar0LsUYyXa7gjsYmZPQ9AoKW0f5YVZ6dRNHcdxtjXc+aiGmNknkvYDjgNulPRa8nNJRxIydhIn7AqYZWbdKSWS6gJ/J6xwLIzCbAlJ9WSp9bpp7XYlCKMNsAyn+SaxmLB9lGBXipRkqyQJddMuXboUptPedNNNHHfccRnVTQFat27Njz/+yLp16xg3bhyvvPJKYYCq4zjO1oY7H9UQSS2A783sYUnLCeevJJ61Au4DjjazxAmwc4Gmkrqb2TtRTr6tmc3KMsRKipRPE07FsniybV/CAXcACwgH270XyxM2NCKcJ3OlFR3slxELSrM/SjqIsM0yALjXzFZKWiSpj5mNk1QHqGlmPxc/O+VPadVNIQSmOo7jbCu4yFj1pAvwnqTpwLXAjUnPBgI7AeMkTZf0opmtIzgHt0r6kCAl/6ti+h8F3B/7Xws8QMh+eZkg+57gDuCCKOXeJKn8YoIs/DXRhumJ82eycCEwApgHfEZRpssfgEslfUSIWfklgKQ3gceBI6KDcnQxfTuO4zhljK98VEPM7GWCI5BMz/hzKnBdhjbTKdqGKan/J4Enk4qujp/0enOAvdPqYWY3kuoQlTTeVEJMSnr5p4RD5tLLD8217/Jg4cKFDBgwgCVLliCJc889l0GDBtGvXz8SEu7Lly+nUaNGTJ8+HYCbb76Zf/3rX9SsWZN77rmHo492f8lxnK0Xdz4cp4IprcLp7Nmzeeyxx5g1axZfffUVRx55JJ988gk1a9asrFdwHMfZIqr1touk1pIqXK9aUgtJT5RcM6VNvqRNDucppn5PSc+X3rpS2XRf0rZI4nNmOY43OcN4XSQ1kvSEpDmSPpZUbGCspJckLS/v+clG8+bN2W+//YBUhdMEZkHhNBF4+swzz/Cb3/yGOnXq0KZNG/bcc0/ee++9yjDdcRynTPCVj0rAzL4iKcBya8XK+OyWHMbLeIaLpAeBl8ysr6TahJTe4tiqFE4XL17MQQcdVPh81113TXFWHMdxtja2OedD0i3AQjO7L94PAX4CmgHHAgbcaGZj0toNJKSDXhzvnwfuMLN8SasIEt7HEfQt/grcBrQELjOzZyXVJJxH0hOoA9xnZv+XxcbWBH2NznHcPkA9YC9CEGZtQrDkWuA4M/s+Nv1DPIOlFnCWmb0nqRswjJBVsho408xSzn7PVieOfRLhi3gP4GkzuyK2OQa4iaDpsczMjojKqPcS4iu2A4aY2TNZ3rET4byX2oQVttOAgsR7xzqXA/XNbEhUO/2AIBJWj5C18hdCcOwYM9skZiT20ZAQizIQIAbHrovPtgmF08WLF/Pxxx8X3n/99dfMmjWLJk2SY3QrFldsTMXnIxWfj1R8PjKQSXlsa/4A+wKvJ93PBs4AxhO+SHcGvgSaA62BmbHeQGB4UrvngZ7x2oBj4/XThEPTtgP2AabH8nOBq+N1HULgZpssNqaPO4+QmtoUWAGcH5/dTXBuIKiBPhCveyS1bwDUitdHAk9amoJnMXUGAp8TFE7rAl8Au0U7FibsJyqUEpyR38frRsAnQL0s73gv0D9e1yZIqxe+dyy/nODAJN7v1ng9iHAuTPM4l4uAnbKMk0dI1R1FcF5GJGxiG1E4vemmm+ymm24qvO/du7e9/fbbZWpPaanOio2Z8PlIxecjleo8H2RRON3mYj4snAvSLMZV7AP8QPiCGm1mG8xsCfA6cEApul0HvBSvZxCcm4J43TqW9wYGxPTSyYR01VxPBptoZivN7FuC85FQ/0zuH2B0fMc3gAZRD6Mh8HiMXbkb6JSh/+LqvGZmKywogM4GWhFOfH3DzObH8RIrL72BK+M75hO+0Ftmead3gL9K+jPQyoo0Q4rj2aT3nmVmX1s4z+VzglOUiVrAfsA/zGxfwirXlZkUTq0KaHxA6RVOTzrpJB577DHWrl3L/Pnz+fTTT+nWrVtFm+04jlNmbHPbLpHHCTEVvwTGAG1yaJOstgmpipsF0YMD2EjYDsHMNkpKzKGASyyksZaW5APTNibdbyT1zyhdmcoIh8JNNLNT4nZOfob+i6uTPPYGiv87IeA0S9vWyYSZPSppMnA88KKk8wgrJdnmONmW5DlI3GezaxGwyMwmx/sngCtLsq8yKa3CaadOnTj99NPp2LEjtWrV4r777vNMF8dxtmq2VedjDEHYqglwGOFk1fNiYGJjwrbFYFK//BYAF0qqQTi+vbS/Wr5MEMyaYGYFktoCi83spy16k1T6ARMlHQKsMLMVMeYhEX04MEu7XOok8y7wd0ltzGy+pMZx9eNl4BJJl5iZSdrXUk+gLUTS7sDnZnaPpJYEPY83CatSOwGrgBMoWlHaLMzsG0kLJbWLTtERwGzbxhROr7rqKq666qpytMpxHKfi2Oa2XQAsyH7vSPjy/5oQp/ER8CEwAbjCzL5JazYJmE/YergHeJ/SMSK2fT9ub/wfZe/crYlqoPcDZ8ey24CbY3m28XKpU0jc/jkXeCoqmiaCc28gxLp8JGlWvM/G6cDMuEXTGfhP3Kq6nhCjMR6YU5ItOXIJ8EhUMs0jxKaAK5w6juNUSZTtNzDHcYpo166dJdRHnZC107Nnz8o2o8rg85GKz0cq1Xk+JE0zs000qrbJlQ/HqcosXLiQXr160bFjRzp16sSwYcMKn9177720b9+eTp06ccUVV6S0+/LLL6lfvz533HFHRZvsOI5TpmyrMR8VSsw6+Z2Z/T2tvAvwULxNiF8tsSxiWbFNa5K0MMrAtoEk6ZeUNXHL4ta04vlmdkoZj7MT8FqGR2cQ9ERqELaE7jWz+4vpp32svx9wlZlV+Dd5Nnn1JUuW8Mwzz/Dhhx9Sp04dli5dmtLuT3/6E8cee2xFm+s4jlPmuPNRNjQinKya4nyY2QxCDAJR1OpyMzuhYk0rXyzzIXXlMc53xLlMJiqadjeztZLqE+JMnrWgIpuJ74FLCcJulULz5s1p3rw5kCqv/sADD3DllVdSp04dAJo1KzrId9y4cbRp04Z69epVis2O4zhliTsfZcMtwB4xuHJ8LEtXU70F6BDrPEgIgn2IoOYJcLGZvV3SQJLeBc6OQbVEZdDLCVoYI4HdgZ+Bc83so7S2owirKk/E+1VmVj86RtcBywmKomMJWhuDCOJgfczsM0lNCcGuCW2Py8xsUhY7DyOoqhLnoQewP0kOmKThBAGaUZIWEHRMjiWkPZ8L3AzsCdyebTXDgqJpgjokbSVmUmk1s6XAUkmpOuclUBHy6oMHD+bNN9/kqquuom7dutxxxx0ccMABrFq1iltvvZXx48f7lovjONsE7nyUDVcCnc0sT9JpwPkE9dMmwBRJb8Q6yV+8OwBHmdkaSXsRvnhzOThuDCGT5FpJzYHmZjZV0r3AB2bWR9LhwH/IsFJQDPsAHQgrA58DI8ysm6RBhGySywjOxN1m9lZMn305tsnE5cBFZjYprkisycGGL+Mc3k1QLD2YkA49k+D0ZETSbsALBEdlsJl9FR2lB4AeiXThHMZP77dC5dVXrFjBjBkzuOWWW5gzZw4nnXQSjz76KPfffz+9e/dm6tSpLFiwgO23377SpZpdLjoVn49UfD5S8fnYFHc+yp5DiGqqwBJJCTXVH9PqbQcMl5RHEPdqm2P/Ywny7tcSnJDE6biHEM5PwcwmSNpJUoNS2D0lpiUj6bM4BoQVkF7x+kigo6REmwaS6pvZqgz9TQLukvQI8JSZLUpql41khdP6ZrYSWClpraRGZrY8UyMzWwjsLakFME7hxOBuZFZpzRkz+yfwTwjZLpf0P7m0XWSloKCAE044gfPPP79Q5bRdu3Zccskl9OrVi169enHHHXfQuXNnvvrqKyZPnsyDDz7I8uXLqVGjBp06deLii8sljCcnqnP0fiZ8PlLx+UjF52NT3PmoPP4ILCGsONQgt5UBzGyxpO8k7U0QHTu/FGMWqrhGMbXaSc9yUVmtARwUpdhLsvMWSS8QDuObFANTi1ORTbahNAqnyWN+FTVWDk1rX6XIJq/ep08fJk6cSK9evfjkk09Yt24dTZo04c033yysM2TIEOrXr1+pjofjOM6W4qm2ZcNKgqgZBBXPfpJqxqX/HgRRreQ6EFRHvzazjQQxrNLoZY8BrgAaJsV1vAn0h8Lg1mVmlr7asoAQdwHhNNvtSjEmhNWQSxI3cdUmI5L2MLMZZnYrMAVoTzi4rqOkOjFD6IhSjp9pnF0lbR+vf0FYAZpLUGntIalNfFbqbZfyIiGvPmHCBPLy8sjLy+PFF1/krLPO4vPPP6dz58785je/4cEHHySH1SLHcZytDl/5KAPM7DtJk+Jv3f+lSE3ViGqqkr4DNkTF0FGEzJgnJQ0gSIyXRob9CUL8RbLC6BBgZFTz/JmQgprOA8Az0YbSjgkhS+S+OEYt4A2yr7xcJqkXYdViFvDfmJEylhDDMZ9wCu2W0gG4U5IRzp65I2YZJWI2noqrPEuBoyT9knDicANgo6TLgI4ZHLVyozh59YcffrjYtkOGDCkHixzHcSoWVzh1nBxwhdNUfA87FZ+PVHw+UqnO8+EKp45TRSitwun48ePZf//96dKlC/vvvz8TJkyoLNMdx3HKBN92qaJUlHLoliLpTIIeSDKTzOyiMh4nWS02wdri1GKrKqVVOG3SpAnPPfccLVq0YObMmRx99NEsXry4hFEcx3GqLu58VCLZZNkhd+XQspRPj6mq95hZ31zbmNm/CXLl5UqyWmw6kv5F0EgR8AkwMEv6b6L+SOAEYGlZydiXhtIqnO67776FbTt16sTq1atZu3ZtYT3HcZytDXc+KpdGZJBll1TLzLZc0aqUREnynB2PKsQfEwGjku4CLiYoymZjFDCcIMSWE5WpcJrMk08+yX777eeOh+M4WzXufFQuybLsBQStjx8IaaltJY0DdiPoYQyLoleJrY6/EOTQPyRqWpSB/PlOxEPtJI2gSHF1F2C4mV0naTBB3KwO8LSZXZul/3oEQbRdCWnEN5jZmCij3tXMlknqSshO6SlpCNCGIA/fkqCDchBBbn0xcKKZFWQaK8nxEEEO3uL9znE+do9VLzCzt83sjXiAX7FUFYXTRLrt/Pnzufrqq7ntttsqXS3RFRtT8flIxecjFZ+PDJiZfyrpA7QGZsbrnoTU1zZJzxvHn9sT0lN3ApoDXwJNCSJhkwiOAcCjwCHxuiXwcTFjPwccHK/rExzRQnuS6rUCPo4/exMUP0UIVn6eIF+eqf/TgAeS7hvGnwuAJvG6K5Afr4cAbxG0R/YhpAsfG589TThfpri5/DdBtG0isEMsG0NwwCA4QA0zzX0un7Zt21pZsm7dOuvdu7fdeeedhWVHH320TZgwofB+9913t6VLl5qZ2cKFC22vvfayt956q0zt2FwmTpxY2SZUKXw+UvH5SKU6zwfh/K5N/k/1bJeqxXsW5cAjl0ZNjncJKyB7AQcSvrC/tXCo2pik+kcSJNunE6TKG8RzVTKRkD+/FGhkGbZ5JNUFHgcuMbMvCM5Hb4I+x/uEFZq9svQ/g6CrcaukQ81sRQ7v/18LqxszCM7CS0l9tS6uoZmdCbQgOEr9YvHhwD/i8w052lDumBWvcAqkKJwuX76c448/nltuuYWDDz64ssx2HMcpM9z5qFoUin5FldIjCcfF70P4wk+XI08nIX+eFz+7WJbASzO7BTiHsKoySVL7DNXuJ5zL8mrCLODmpP73NLN/Zen/E2A/guNwo6Rr4qNkifWM8uoWVF8LotcMucurbwAeI55xU1UprcLp8OHDmTdvHtdff31h/UQmjOM4ztaIx3xULumS68k0BH4ws5+jY3BQLJ8MDJO0E+Gwul8T4j6gSP78dgjy52Y2PVPnCflzYIakAwirGNOTnl8E7BidlAQvAzdIesTMVknaheAkbPJNGDNnvjezhyUtJzg6UCTx/l/KwEmIcR57mNm8eH0SMCc+fg24ABgqqSbhsLpKX/0orcLp1VdfzdVXX13eZjmO41QYvvJRiZjZd4RVh5lEhyGJl4Bakj4mBKa+G9t8TYiPeIewdfJxUptLga6SPpI0m+IPnbtM0swolV5AcAaSuRzoIml6/JxvZq8Q4krekTSDIPOezXnqArwXt4CuBW6M5dcRnKephNN8txQBD0Z7ZhBiYq6PzwYBveKzaUBHAEmjCfPXTtIiSWeXgR2O4zhOjvjKRyVjZr/LUr6WkOmR6VlGbQ0zW0ZRvENJ416SoXgB0Dk+b5Ol3TCKsmSK6z+jTomZvQm0zVA+JO2+frZnafU2AhkDIcxsCXByhvLfZre8/Fm4cCEDBgxgyZIlSOLcc89l0KCg03bvvfdy3333UbNmTY4//nhuu+02vvvuO/r27cuUKVMYOHAgw4cPr0zzHcdxthh3PhyngimtwmndunW54YYbmDlzJjNnzqxk6x3HcbYc33apYCS1jtss6eUjJHXMUD5Q0mb/qivpzKStk8Tnvs3tL4NtIzL0Pz3GpJQpkp7OMM7R8dnekt6RNEvSjJipk62f9rHuWkmXl7WdJdG8eXP2228/IFXh9B//+EdGhdN69epxyCGHULduSfHGjuM4Wwe+8lFFMLNzSq61Wf1m3KKJwZmK2xZbwhozy9vCPnLCspxrI6kW8DDwBzP7MDo+GQXJIt8T4mP65Dp2VVE4dRzH2RZw56NyqCXpEUIq6ixgAPAicLmZTc2mYJoJSb8mBHRuAFaYWY943ssphIyZXYCHLaiTtibEYUwmZJwcJ+l0MiiWllZdtZS2FZ5FI+l5gsppvqRVBF2O44Cvgb8CtxEE0y4zs2ezDNUb+MjMPoTCQN6EDccANxF0Q5aZ2RExO2eppOMz9lbUtkopnM6ZM4fFixdXCaVEV2xMxecjFZ+PVHw+MpBJecw/5a5qahSpi44kZJbkExQ/syqYZulvBrBLvG4Ufw4kfHnvRJE6atc49kaCFggUo1hKKdVVS2nb8KQ6zwM947WRqmr6CkWKp9OLGecywom3LxPEz66I5U2BhUTV2MQ7JbUbQnD4Svxzq2yFUzOzf//733bRRReVqR2bS3VWbMyEz0cqPh+pVOf5wBVOqxQLrejMlYeBQ5KeFadgmolJwChJ/4/w232C8Wb2nZmtBp5KGuMLM3s3XhenWFpaddXS2JaNdaSqmr5uRYqnrYtpVyu+X//48xRJRxC0Ud6wqBprZt/nYEO5Y1Y6hVPHcZxtDd92qRzSFaYyK07l0pHZ+ZIOBI4Hpknav4QxfkoqSyiW/l9yxTR11Z8l5VOyumqutiUrnJLWb7qqaaHiaYzryMYigpOxLNr/ImFLa04xbSqNhMJply5dyMvLA+Cmm27irLPO4qyzzqJz587Url27UOEUoHXr1vz444+sW7eOcePG8corr9Cx4ybxyY7jOFsF7nxUDi0ldTezd4DfEQ5UOzE+K07BdBOiUulkYLKkYwmrFBDOVWkMrCYEVp6VoXlGxVI2T101V9sWABdKqkGIR+mWdZZy52XgCkk7EFZPDgPuBt4D/i6pjZnNl9S4Kqx+lFbhFEJgquM4zraCOx+Vw1zgIkkjgdmEIMsTISiYKhwv/w4hqHN6CX3dLmkvwirGawRnII/wxfsk4Uj7hy0EsrZObmhmr0jqQFAsBVgF/J6w9XF+VFedS5K6ahnYBjA/vvfHhO2eLcLMfpB0FzCFsMLzopm9AIVBo09FZ2cpwSn7JTAVaABslHQZ0NHMftxSWxzHcZySceejgjGzBYTYinR6JtXJmB6bpb9T08uiI7HIzPpkGLtzWlk2xdJSqavmalukf5b6WVVNk59lafswIX4mvfy/pEnHm9k3BKfMcRzHqQQ84NRxHMdxnArFVz62EiRdRYixSOZxM/vf9LpmNgoYVQFmAaWzbQvHORq4Na14vmURH3Mcx3GqJu58bCXEL/Iy/TIvKyrKNstyWJ3jOI6zdeHbLo7jOI7jVCjKlvLnOE4RklYSMn+cQBNgWWUbUYXw+UjF5yOV6jwfrcysaXqhb7s4Tm7MNbOulW1EVUHSVJ+PInw+UvH5SMXnY1N828VxHMdxnArFnQ/HcRzHcSoUdz4cJzf+WdkGVDF8PlLx+UjF5yMVn480PODUcRzHcZwKxVc+HMdxHMepUNz5cBzHcRynQnHnw3GKQdIxkuZKmifpysq2pzyRNFLSUkkzk8oaSxov6dP48xexXJLuifPykaT9ktqcEet/KumMyniXLUXSbpImSpotaZakQbG8us5HXUnvSfowzsd1sbyNpMnxvcdIqh3L68T7efF566S+/hLL58YjE7ZaJNWU9IGk5+N9tZ6PUmFm/vGPfzJ8gJrAZ8DuQG3gQ6BjZdtVju/bA9gPmJlUdhtwZby+Erg1Xh9HOC1YwEHA5FjeGPg8/vxFvP5FZb/bZsxFc2C/eL0j8AnQsRrPh4D68Xo7YHJ8z7HAb2L5/cAF8fpC4P54/RtgTLzuGP8d1QHaxH9fNSv7/bZgXv4EPAo8H++r9XyU5uMrH46TnW7APDP73MzWAY8BJ1eyTeWGmb0BfJ9WfDLwYLx+EOiTVP4fC7wLNJLUHDgaGG9m35vZD8B44JhyN76MMbOvzez9eL0S+BjYheo7H2Zmq+LtdvFjwOHAE7E8fT4S8/QEcIQkxfLHzGytmc0H5hH+nW11SNoVOB4YEe9FNZ6P0uLOh+NkZxdgYdL9olhWndjZzL6O198AO8frbHOzzc1ZXCLfl/DbfrWdj7jFMB1YSnCiPgOWm9n6WCX53QrfOz5fAezENjQfwFDgCmBjvN+J6j0fpcKdD8dxcsLCOnG1ys2XVB94ErjMzH5Mflbd5sPMNphZHrAr4bfz9pVrUeUh6QRgqZlNq2xbtlbc+XCc7CwGdku63zWWVSeWxO0D4s+lsTzb3GwzcyZpO4Lj8YiZPRWLq+18JDCz5cBEoDtheylxRljyuxW+d3zeEPiObWc+DgZOkrSAsB17ODCM6jsfpcadD8fJzhRgrxjBXpsQKPZsJdtU0TwLJDI0zgCeSSofELM8DgJWxO2Il4Hekn4RM0F6x7Ktirgf/y/gYzO7K+lRdZ2PppIaxevtgaMIcTATgb6xWvp8JOapLzAhrhQ9C/wmZn+0AfYC3quQlyhDzOwvZrarmbUm/L8wwcz6U03nY7Oo7IhX//inKn8IWQyfEPa3r6pse8r5XUcDXwMFhL3nswn70q8BnwKvAo1jXQH3xXmZAXRN6ucsQuDcPODMyn6vzZyLQwhbKh8B0+PnuGo8H3sDH8T5mAlcE8t3J3xZzgMeB+rE8rrxfl58vntSX1fFeZoLHFvZ71YGc9OTomyXaj8fuX5cXt1xHMdxnArFt10cx3Ecx6lQ3PlwHMdxHKdCcefDcRzHcZwKxZ0Px3Ecx3EqFHc+HMdxHMepUNz5cBynWiNpg6TpSZ/Wm9FHH0kdy8E8JLWQ9ETJNct0zDxJx1XkmE71olbJVRzHcbZpVluQDd8S+gDPA7NzbSCplhWdA5IVM/uKIuGqcicqcOYBXYEXK2pcp3rhKx+O4zhpSNpf0uuSpkl6OUlS/f9JmiLpQ0lPStpB0q+Ak4Db48rJHpLyJXWNbZpEGW4kDZT0rKQJwGuS6kkaKek9SR9I2uTUZEmtJc1Maj9O0nhJCyRdLOlPse27khrHevmShkV7ZkrqFssbx/Yfxfp7x/Ihkh6SNAl4CLge6Bfb95PUTdI7cZy3JbVLsucpSS9J+lTSbUl2HyPp/ThXr8WyEt/XqR74yofjONWd7eNprQDzgdOBe4GTzexbSf2A/yUolT5lZg8ASLoRONvM7pX0LEHl8on4rLjx9gP2NrPvJd1EkNo+K8qXvyfpVTP7qZj2nQmn7NYlKGb+2cz2lXQ3MIBw2irADmaWJ6kHMDK2uw74wMz6SDoc+A9hlQOgI3CIma2WNJCg0npxfJ8GwKFmtl7SkcBNwGmxXV60Zy0wV9K9wBrgAaCHmc1POEUENc/Svq+zDeLOh+M41Z2UbRdJnQlf1OOjE1GTIDsP0Dk6HY2A+mzeOS3jzez7eN2bcEDZ5fG+LtCScG5KNiaa2UpgpaQVwHOxfAZBBj3BaAAze0NSg/hlfwjRaTCzCZJ2io4FwLNmtjrLmA2BByXtRZCd3y7p2WtmtgJA0mygFfAL4A0zmx/H2pL3dbZB3PlwHMdJRcAsM+ue4dkooI+ZfRhXB3pm6WM9RdvaddOeJf+WL+A0M5tbCvvWJl1vTLrfSOr/6elnZ5R0lkZxqw83EJyeU2JAbn4WezZQ/PfK5ryvsw3iMR+O4zipzAWaSuoOIGk7SZ3isx2BryVtB/RParMyPkuwANg/XhcXLPoycIniEoukfbfc/EL6xT4PIZyyuwJ4k2i3pJ7AMjP7MUPb9PdpSNFR7wNzGPtdoIfCSa0kbbuU5/s6WxHufDiO4yRhZusIDsOtkj4knGj7q/j4b8BkYBIwJ6nZY8DgGES5B3AHcIGkD4AmxQx3A2EL4yNJs+J9WbEmjn8/4YRigCHA/pI+Am6h6Jj3dCYCHRMBp8BtwM2xvxJXzM3sW+Bc4Kk4h2Pio/J8X2crwk+1dRzH2caQlA9cbmZTK9sWx8mEr3w4juM4jlOh+MqH4ziO4zgViq98OI7jOI5Tobjz4TiO4zhOheLOh+M4juM4FYo7H47jOI7jVCjufDiO4ziOU6H8f1hmnAKY64ZwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=2021\n",
    "params0 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "seed1=42\n",
    "params1 = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "seed2 = 29\n",
    "params2 = {\n",
    "        'learning_rate': 0.15,        \n",
    "        'lambda_l1': 2.154360665259325,\n",
    "        'lambda_l2': 6.711089761523827,\n",
    "        'num_leaves': 2769,\n",
    "        'min_sum_hessian_in_leaf': 20.44437160769411,\n",
    "        'feature_fraction': 0.7921473067441019,\n",
    "        'feature_fraction_bynode': 0.8083803860191322,\n",
    "        'bagging_fraction': 0.9726755660563261,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 1690,\n",
    "        'max_depth': 4,\n",
    "        'seed': seed2,\n",
    "        'feature_fraction_seed': seed2,\n",
    "        'bagging_seed': seed2,\n",
    "        'drop_seed': seed2,\n",
    "        'data_random_seed': seed2,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    } \n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params,boost=1000):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=boost,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=50,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb= train_and_evaluate_lgb(train, test,params0)\n",
    "predictions_lgb2= train_and_evaluate_lgb(train, test,params2,boost=10000)\n",
    "test['target'] = predictions_lgb\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf8d067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:13:38.404462Z",
     "iopub.status.busy": "2021-09-02T14:13:38.403800Z",
     "iopub.status.idle": "2021-09-02T14:13:38.407282Z",
     "shell.execute_reply": "2021-09-02T14:13:38.406743Z",
     "shell.execute_reply.started": "2021-08-30T09:48:18.063276Z"
    },
    "papermill": {
     "duration": 0.061266,
     "end_time": "2021-09-02T14:13:38.407430",
     "exception": false,
     "start_time": "2021-09-02T14:13:38.346164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428932, 248)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a97bea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:13:38.524069Z",
     "iopub.status.busy": "2021-09-02T14:13:38.523357Z",
     "iopub.status.idle": "2021-09-02T14:13:44.640298Z",
     "shell.execute_reply": "2021-09-02T14:13:44.639642Z",
     "shell.execute_reply.started": "2021-08-30T09:48:18.071101Z"
    },
    "papermill": {
     "duration": 6.177737,
     "end_time": "2021-09-02T14:13:44.640485",
     "exception": false,
     "start_time": "2021-09-02T14:13:38.462748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c03f271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:13:44.763910Z",
     "iopub.status.busy": "2021-09-02T14:13:44.758696Z",
     "iopub.status.idle": "2021-09-02T14:13:56.347444Z",
     "shell.execute_reply": "2021-09-02T14:13:56.348208Z",
     "shell.execute_reply.started": "2021-08-30T09:48:25.093899Z"
    },
    "papermill": {
     "duration": 11.653877,
     "end_time": "2021-09-02T14:13:56.348471",
     "exception": false,
     "start_time": "2021-09-02T14:13:44.694594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465e4bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:13:56.486389Z",
     "iopub.status.busy": "2021-09-02T14:13:56.485683Z",
     "iopub.status.idle": "2021-09-02T14:14:27.402964Z",
     "shell.execute_reply": "2021-09-02T14:14:27.402094Z",
     "shell.execute_reply.started": "2021-08-30T09:48:37.824504Z"
    },
    "papermill": {
     "duration": 30.983596,
     "end_time": "2021-09-02T14:14:27.403189",
     "exception": false,
     "start_time": "2021-09-02T14:13:56.419593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#colNames.remove('row_id')\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "train_nn=train[colNames].copy()\n",
    "test_nn=test[colNames].copy()\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "    train_nn[col] = qt.fit_transform(train_nn[[col]])\n",
    "    test_nn[col] = qt.transform(test_nn[[col]])    \n",
    "    qt_train.append(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef313d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:27.523575Z",
     "iopub.status.busy": "2021-09-02T14:14:27.522296Z",
     "iopub.status.idle": "2021-09-02T14:14:27.531689Z",
     "shell.execute_reply": "2021-09-02T14:14:27.531041Z",
     "shell.execute_reply.started": "2021-08-30T09:49:07.242658Z"
    },
    "papermill": {
     "duration": 0.071595,
     "end_time": "2021-09-02T14:14:27.531830",
     "exception": false,
     "start_time": "2021-09-02T14:14:27.460235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_nn[['stock_id','time_id','target']]=train[['stock_id','time_id','target']]\n",
    "test_nn[['stock_id','time_id']]=test[['stock_id','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09806983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:27.653790Z",
     "iopub.status.busy": "2021-09-02T14:14:27.653152Z",
     "iopub.status.idle": "2021-09-02T14:14:29.894699Z",
     "shell.execute_reply": "2021-09-02T14:14:29.893769Z",
     "shell.execute_reply.started": "2021-08-30T09:49:07.262216Z"
    },
    "papermill": {
     "duration": 2.310148,
     "end_time": "2021-09-02T14:14:29.894886",
     "exception": false,
     "start_time": "2021-09-02T14:14:27.584738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "# making agg features\n",
    "from sklearn.cluster import KMeans\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train_nn.loc[train_nn['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test_nn.loc[test_nn['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6049dc8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:30.013058Z",
     "iopub.status.busy": "2021-09-02T14:14:30.012016Z",
     "iopub.status.idle": "2021-09-02T14:14:30.015345Z",
     "shell.execute_reply": "2021-09-02T14:14:30.014773Z",
     "shell.execute_reply.started": "2021-08-30T09:49:09.042483Z"
    },
    "papermill": {
     "duration": 0.065385,
     "end_time": "2021-09-02T14:14:30.015492",
     "exception": false,
     "start_time": "2021-09-02T14:14:29.950107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab204f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:30.139540Z",
     "iopub.status.busy": "2021-09-02T14:14:30.138784Z",
     "iopub.status.idle": "2021-09-02T14:14:30.218366Z",
     "shell.execute_reply": "2021-09-02T14:14:30.218964Z",
     "shell.execute_reply.started": "2021-08-30T09:49:09.054213Z"
    },
    "papermill": {
     "duration": 0.146939,
     "end_time": "2021-09-02T14:14:30.219153",
     "exception": false,
     "start_time": "2021-09-02T14:14:30.072214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ffab780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:30.340413Z",
     "iopub.status.busy": "2021-09-02T14:14:30.339569Z",
     "iopub.status.idle": "2021-09-02T14:14:31.481102Z",
     "shell.execute_reply": "2021-09-02T14:14:31.480583Z",
     "shell.execute_reply.started": "2021-08-30T09:49:09.239588Z"
    },
    "papermill": {
     "duration": 1.204905,
     "end_time": "2021-09-02T14:14:31.481263",
     "exception": false,
     "start_time": "2021-09-02T14:14:30.276358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "train_nn = pd.merge(train_nn,mat1[nnn],how='left',on='time_id')\n",
    "test_nn = pd.merge(test_nn,mat2[nnn],how='left',on='time_id')\n",
    "del mat1,mat2\n",
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00320d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:31.605772Z",
     "iopub.status.busy": "2021-09-02T14:14:31.605083Z",
     "iopub.status.idle": "2021-09-02T14:14:31.622029Z",
     "shell.execute_reply": "2021-09-02T14:14:31.622540Z",
     "shell.execute_reply.started": "2021-08-30T09:49:14.890567Z"
    },
    "papermill": {
     "duration": 0.084846,
     "end_time": "2021-09-02T14:14:31.622720",
     "exception": false,
     "start_time": "2021-09-02T14:14:31.537874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "\n",
    "cat_data = train_nn['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(244,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d339b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:31.736605Z",
     "iopub.status.busy": "2021-09-02T14:14:31.735885Z",
     "iopub.status.idle": "2021-09-02T14:14:31.741578Z",
     "shell.execute_reply": "2021-09-02T14:14:31.740949Z",
     "shell.execute_reply.started": "2021-08-30T09:49:14.922612Z"
    },
    "papermill": {
     "duration": 0.063257,
     "end_time": "2021-09-02T14:14:31.741717",
     "exception": false,
     "start_time": "2021-09-02T14:14:31.678460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "935bc88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:14:31.874934Z",
     "iopub.status.busy": "2021-09-02T14:14:31.873525Z",
     "iopub.status.idle": "2021-09-02T14:28:16.954967Z",
     "shell.execute_reply": "2021-09-02T14:28:16.954430Z",
     "shell.execute_reply.started": "2021-08-30T09:49:14.930362Z"
    },
    "papermill": {
     "duration": 825.157326,
     "end_time": "2021-09-02T14:28:16.955148",
     "exception": false,
     "start_time": "2021-09-02T14:14:31.797822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 4s 17ms/step - loss: 23.6469 - val_loss: 0.6022\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9385 - val_loss: 0.4826\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7018 - val_loss: 0.3841\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6264 - val_loss: 0.7295\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6640 - val_loss: 0.5552\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6174 - val_loss: 0.4912\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6060 - val_loss: 0.4393\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7283 - val_loss: 0.3372\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4916 - val_loss: 0.4816\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.5007 - val_loss: 0.3925\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4358 - val_loss: 0.5666\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4526 - val_loss: 0.4483\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3919 - val_loss: 0.4082\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3776 - val_loss: 0.2452\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2309 - val_loss: 0.2445\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2391 - val_loss: 0.2351\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2365 - val_loss: 0.2790\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9028 - val_loss: 0.2430\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2628 - val_loss: 0.2209\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2243 - val_loss: 0.2226\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2245 - val_loss: 0.2232\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2282 - val_loss: 0.2417\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2221 - val_loss: 0.2121\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2182 - val_loss: 0.2147\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2247 - val_loss: 0.2220\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2318 - val_loss: 0.2488\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2263 - val_loss: 0.2230\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2279 - val_loss: 0.2156\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2389 - val_loss: 0.2149\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2314 - val_loss: 0.2305\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2135 - val_loss: 0.2104\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2072 - val_loss: 0.2092\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2069 - val_loss: 0.2085\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2065 - val_loss: 0.2095\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2059 - val_loss: 0.2084\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2065 - val_loss: 0.2083\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2071 - val_loss: 0.2085\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2062 - val_loss: 0.2085\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2069 - val_loss: 0.2081\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2073 - val_loss: 0.2101\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2068 - val_loss: 0.2100\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2069 - val_loss: 0.2135\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2072 - val_loss: 0.2092\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2086 - val_loss: 0.2094\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2063 - val_loss: 0.2079\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2080 - val_loss: 0.2141\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2076 - val_loss: 0.2079\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2073 - val_loss: 0.2083\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2073 - val_loss: 0.2143\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2082 - val_loss: 0.2507\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2226 - val_loss: 0.2102\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2127 - val_loss: 0.2116\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2034 - val_loss: 0.2093\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2034 - val_loss: 0.2078\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2078\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2020 - val_loss: 0.2096\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2072\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2081\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2011 - val_loss: 0.2075\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2027 - val_loss: 0.2082\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2077\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2075\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2073\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2093\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2077\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2084\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2000 - val_loss: 0.2075\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2014 - val_loss: 0.2074\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1999 - val_loss: 0.2075\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2000 - val_loss: 0.2075\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2002 - val_loss: 0.2076\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2010 - val_loss: 0.2075\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1995 - val_loss: 0.2076\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1996 - val_loss: 0.2076\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2004 - val_loss: 0.2076\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2001 - val_loss: 0.2074\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2003 - val_loss: 0.2074\n",
      "Fold 1 NN: 0.20723\n",
      "CV 2/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 25.6537 - val_loss: 0.8559\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.1910 - val_loss: 0.8187\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.7422 - val_loss: 0.4812\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4206 - val_loss: 1.3784\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9274 - val_loss: 0.6026\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6896 - val_loss: 1.0980\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7212 - val_loss: 0.7435\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8847 - val_loss: 0.6354\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4571 - val_loss: 0.3183\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5114 - val_loss: 0.2716\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2856 - val_loss: 0.3103\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3219 - val_loss: 0.2715\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2943 - val_loss: 0.4203\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2921 - val_loss: 0.2885\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5055 - val_loss: 0.9070\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.7511 - val_loss: 0.2407\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2324 - val_loss: 0.2261\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2382 - val_loss: 0.3284\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2626 - val_loss: 0.2290\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2573 - val_loss: 0.2321\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2445 - val_loss: 0.2635\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2462 - val_loss: 0.3074\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2586 - val_loss: 0.2215\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2484 - val_loss: 0.2493\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2544 - val_loss: 0.2752\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2501 - val_loss: 0.2872\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2557 - val_loss: 0.2226\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2517 - val_loss: 0.2923\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2424 - val_loss: 0.2600\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2495 - val_loss: 0.2950\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2190 - val_loss: 0.2167\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2065 - val_loss: 0.2147\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2067 - val_loss: 0.2148\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2059 - val_loss: 0.2144\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2042 - val_loss: 0.2133\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2063 - val_loss: 0.2147\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2058 - val_loss: 0.2137\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2045 - val_loss: 0.2139\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2155\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2299\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2079 - val_loss: 0.2167\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2075 - val_loss: 0.2159\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2146\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2134\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2126\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2138\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2014 - val_loss: 0.2127\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2017 - val_loss: 0.2139\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2123\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2011 - val_loss: 0.2137\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2136\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2126\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2007 - val_loss: 0.2145\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2135\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2013 - val_loss: 0.2163\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2157\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2007 - val_loss: 0.2132\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1999 - val_loss: 0.2129\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1997 - val_loss: 0.2123\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1997 - val_loss: 0.2144\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1998 - val_loss: 0.2138\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1992 - val_loss: 0.2120\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2000 - val_loss: 0.2147\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1995 - val_loss: 0.2139\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2000 - val_loss: 0.2140\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2002 - val_loss: 0.2133\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1996 - val_loss: 0.2144\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2000 - val_loss: 0.2131\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1998 - val_loss: 0.2130\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1991 - val_loss: 0.2128\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1990 - val_loss: 0.2134\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1988 - val_loss: 0.2132\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1987 - val_loss: 0.2135\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1989 - val_loss: 0.2131\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1992 - val_loss: 0.2132\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.1997 - val_loss: 0.2136\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1989 - val_loss: 0.2134\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1989 - val_loss: 0.2134\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1997 - val_loss: 0.2133\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1986 - val_loss: 0.2135\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.1993 - val_loss: 0.2133\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1994 - val_loss: 0.2137\n",
      "Fold 2 NN: 0.21197\n",
      "CV 3/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 25.2220 - val_loss: 0.7353\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6448 - val_loss: 0.4126\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3282 - val_loss: 0.2697\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3507 - val_loss: 0.3738\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5997 - val_loss: 0.7062\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6362 - val_loss: 0.3790\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4498 - val_loss: 0.4391\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4217 - val_loss: 0.3939\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.4078 - val_loss: 0.2245\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2473 - val_loss: 0.2299\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2484 - val_loss: 0.2259\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2508 - val_loss: 0.2182\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2405 - val_loss: 0.2710\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2499 - val_loss: 0.2338\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2665 - val_loss: 0.3022\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2507 - val_loss: 0.2413\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2671 - val_loss: 0.3131\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2512 - val_loss: 0.2399\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2635 - val_loss: 0.2272\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2095 - val_loss: 0.2115\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2071 - val_loss: 0.2124\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2072 - val_loss: 0.2121\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2077 - val_loss: 0.2109\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2068 - val_loss: 0.2114\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2075 - val_loss: 0.2117\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2079 - val_loss: 0.2107\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2073 - val_loss: 0.2134\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2091 - val_loss: 0.2223\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2170 - val_loss: 0.2157\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2138 - val_loss: 0.2113\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2059 - val_loss: 0.2240\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2104 - val_loss: 0.2246\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2110 - val_loss: 0.2127\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2094\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2094\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2095\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2121\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2023 - val_loss: 0.2103\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2020 - val_loss: 0.2104\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2109\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2103\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2027 - val_loss: 0.2094\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2016 - val_loss: 0.2096\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2009 - val_loss: 0.2098\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2097\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2102\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2014 - val_loss: 0.2097\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2095\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2007 - val_loss: 0.2096\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2011 - val_loss: 0.2097\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2095\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2011 - val_loss: 0.2094\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2020 - val_loss: 0.2096\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2006 - val_loss: 0.2095\n",
      "Fold 3 NN: 0.20937\n",
      "CV 4/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 21.1126 - val_loss: 0.5299\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6890 - val_loss: 0.6678\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7261 - val_loss: 1.1119\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.7094 - val_loss: 0.7064\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 1.1180 - val_loss: 0.5761\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5247 - val_loss: 0.4745\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5739 - val_loss: 0.4975\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5594 - val_loss: 0.3834\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3919 - val_loss: 0.4388\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8410 - val_loss: 0.3304\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2606 - val_loss: 0.2388\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2391 - val_loss: 0.3023\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2464 - val_loss: 0.2528\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2401 - val_loss: 0.2270\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2457 - val_loss: 0.2998\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2484 - val_loss: 0.2265\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2571 - val_loss: 0.2350\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3942 - val_loss: 3.3993\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7519 - val_loss: 0.2259\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2345 - val_loss: 0.2267\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2264 - val_loss: 0.2413\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2230 - val_loss: 0.2276\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2328 - val_loss: 0.2263\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2267 - val_loss: 0.2200\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2206 - val_loss: 0.2366\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2380 - val_loss: 0.2226\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2227 - val_loss: 0.2239\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2309 - val_loss: 0.2329\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2291 - val_loss: 0.2176\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2342 - val_loss: 0.2296\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2390 - val_loss: 0.2265\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2272 - val_loss: 0.2299\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2384 - val_loss: 0.5505\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.3873 - val_loss: 0.2252\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2305 - val_loss: 0.2220\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2219 - val_loss: 0.2200\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2081 - val_loss: 0.2148\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2057 - val_loss: 0.2148\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2059 - val_loss: 0.2148\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2055 - val_loss: 0.2168\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2054 - val_loss: 0.2152\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2046 - val_loss: 0.2196\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2067 - val_loss: 0.2149\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2041 - val_loss: 0.2165\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2027 - val_loss: 0.2139\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2147\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2150\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2026 - val_loss: 0.2144\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2025 - val_loss: 0.2157\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2026 - val_loss: 0.2145\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2145\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2145\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2144\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2144\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2029 - val_loss: 0.2146\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2149\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2143\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2142\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2146\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2023 - val_loss: 0.2145\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2021 - val_loss: 0.2145\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2143\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2144\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2019 - val_loss: 0.2145\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2144\n",
      "Fold 4 NN: 0.21387\n",
      "CV 5/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 33.4685 - val_loss: 1.5088\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7567 - val_loss: 0.5882\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5870 - val_loss: 0.3505\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4380 - val_loss: 0.8100\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5640 - val_loss: 0.3322\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5526 - val_loss: 0.3633\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3134 - val_loss: 0.2526\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2651 - val_loss: 0.2401\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2790 - val_loss: 0.2964\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2825 - val_loss: 0.2862\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2781 - val_loss: 0.3029\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2994 - val_loss: 0.4561\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2872 - val_loss: 0.2462\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3186 - val_loss: 0.2300\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2710 - val_loss: 0.2505\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.0124 - val_loss: 0.3063\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2703 - val_loss: 0.2255\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2471 - val_loss: 0.2249\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2297 - val_loss: 0.2264\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2269 - val_loss: 0.2283\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2331 - val_loss: 0.2291\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2304 - val_loss: 0.2296\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2266 - val_loss: 0.2235\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2354 - val_loss: 0.2606\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2334 - val_loss: 0.2399\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2331 - val_loss: 0.2415\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2705 - val_loss: 0.3703\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2521 - val_loss: 0.2272\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2380 - val_loss: 0.2353\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2330 - val_loss: 0.2427\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2132 - val_loss: 0.2159\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2078 - val_loss: 0.2148\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2062 - val_loss: 0.2155\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2066 - val_loss: 0.2148\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2072 - val_loss: 0.2169\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2158\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2058 - val_loss: 0.2166\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2070 - val_loss: 0.2146\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2158\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2061 - val_loss: 0.2184\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2071 - val_loss: 0.2138\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2055 - val_loss: 0.2340\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2080 - val_loss: 0.2199\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2108 - val_loss: 0.2148\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2227\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2084 - val_loss: 0.2182\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2074 - val_loss: 0.2158\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2113 - val_loss: 0.2155\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2129\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2027 - val_loss: 0.2131\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2143\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2141\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2137\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2145\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2028 - val_loss: 0.2132\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2020 - val_loss: 0.2160\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2011 - val_loss: 0.2129\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2016 - val_loss: 0.2129\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2002 - val_loss: 0.2131\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2006 - val_loss: 0.2135\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2007 - val_loss: 0.2133\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2133\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2005 - val_loss: 0.2140\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2001 - val_loss: 0.2127\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2005 - val_loss: 0.2128\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2004 - val_loss: 0.2130\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2005 - val_loss: 0.2129\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2129\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2008 - val_loss: 0.2135\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2003 - val_loss: 0.2129\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2128\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2002 - val_loss: 0.2129\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2016 - val_loss: 0.2131\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2006 - val_loss: 0.2129\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2007 - val_loss: 0.2130\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2007 - val_loss: 0.2129\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2009 - val_loss: 0.2129\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2001 - val_loss: 0.2129\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2001 - val_loss: 0.2129\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2129\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2000 - val_loss: 0.2129\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2004 - val_loss: 0.2129\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2129\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2007 - val_loss: 0.2130\n",
      "Fold 5 NN: 0.21267\n"
     ]
    }
   ],
   "source": [
    "target_name='target'\n",
    "scores_folds = {}\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train_nn)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train_nn[features_to_consider] = train_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "test_nn[features_to_consider] = test_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "\n",
    "train_nn[pred_name] = 0\n",
    "test_nn[target_name] = 0\n",
    "test_predictions_nn = np.zeros(test_nn.shape[0])\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train_nn.loc[train_nn.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train_nn.loc[train_nn.time_id.isin(indexes), target_name]\n",
    "    X_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.006),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test_nn[features_to_consider].values)\n",
    "    #test_nn[target_name] += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    test_predictions_nn += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a092f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T14:28:25.201824Z",
     "iopub.status.busy": "2021-09-02T14:28:25.201164Z",
     "iopub.status.idle": "2021-09-02T14:28:25.227530Z",
     "shell.execute_reply": "2021-09-02T14:28:25.228035Z",
     "shell.execute_reply.started": "2021-08-30T10:06:01.102575Z"
    },
    "papermill": {
     "duration": 4.16287,
     "end_time": "2021-09-02T14:28:25.228232",
     "exception": false,
     "start_time": "2021-09-02T14:28:21.065362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE NN: 1.0 - Folds: [0.20723, 0.21197, 0.20937, 0.21387, 0.21267]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-34</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.001992\n",
       "1   0-32  0.002185\n",
       "2   0-34  0.002185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_nn[\"row_id\"] = test_nn[\"stock_id\"].astype(str) + \"-\" + test_nn[\"time_id\"].astype(str)\n",
    "pred_lgb_m = predictions_lgb*0.6+predictions_lgb2*0.4\n",
    "test_nn[target_name] = test_predictions_nn*0.585 + pred_lgb_m*0.415\n",
    "\n",
    "score = round(rmspe(y_true = train_nn[target_name].values, y_pred = train_nn[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "display(test_nn[['row_id', target_name]].head(3))\n",
    "test_nn[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "#test[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "#kmeans N=5 [0.2101, 0.21399, 0.20923, 0.21398, 0.21175]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2633.371027,
   "end_time": "2021-09-02T14:28:32.144487",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-02T13:44:38.773460",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
